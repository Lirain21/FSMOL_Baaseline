{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c583b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pyprojroot import here as project_root\n",
    "\n",
    "sys.path.insert(0, str(project_root()))\n",
    "\n",
    "from fs_mol.data.dkt import get_dkt_batcher\n",
    "from fs_mol.utils.torch_utils import torchify\n",
    "\n",
    "from bayes_opt.bo_utils import load_antibiotics_dataset, run_gp_ei_bo, min_so_far, task_to_batches, ADKTModelFeatureExtractor\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b7123ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping datapoint O=C([O-])C=CC(=O)[O-].[Fe+2], cannot featurise with current metadata.\n",
      "Skipping datapoint CC(O)CN1CCN(CC(=O)[O-])CCN(CC(=O)[O-])CCN(CC(=O)[O-])CC1.[Gd+3], cannot featurise with current metadata.\n"
     ]
    }
   ],
   "source": [
    "task = load_antibiotics_dataset(\"antibiotics-dataset.xlsx\", \"../../fs_mol/preprocessing/utils/helper_files/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ac1070b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batcher = get_dkt_batcher(max_num_graphs=100)\n",
    "dkt_batches = torchify(\n",
    "    task_to_batches(task, batcher), \n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a342b4f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ADKTModelFeatureExtractor(\n",
       "  (graph_feature_extractor): GraphFeatureExtractor(\n",
       "    (init_node_proj): Linear(in_features=32, out_features=128, bias=False)\n",
       "    (gnn): GNN(\n",
       "      (gnn_blocks): ModuleList(\n",
       "        (0): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (6): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (7): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (8): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (9): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (readout): CombinedGraphReadout(\n",
       "      (_weighted_mean_pooler): MultiHeadWeightedGraphReadout(\n",
       "        (_scoring_module): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=12, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_transformation_mlp): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_combination_layer): Linear(in_features=768, out_features=512, bias=False)\n",
       "      )\n",
       "      (_weighted_sum_pooler): MultiHeadWeightedGraphReadout(\n",
       "        (_scoring_module): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=12, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_transformation_mlp): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_combination_layer): Linear(in_features=768, out_features=512, bias=False)\n",
       "      )\n",
       "      (_max_pooler): UnweightedGraphReadout(\n",
       "        (_combination_layer): Linear(in_features=1408, out_features=512, bias=False)\n",
       "      )\n",
       "      (_combination_layer): Linear(in_features=1536, out_features=512, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2560, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  )\n",
       "  (gp_likelihood): GaussianLikelihood(\n",
       "    (noise_covar): HomoskedasticNoise(\n",
       "      (noise_prior): LogNormalPrior()\n",
       "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "    )\n",
       "  )\n",
       "  (gp_model): ExactGPLayer(\n",
       "    (likelihood): GaussianLikelihood(\n",
       "      (noise_covar): HomoskedasticNoise(\n",
       "        (noise_prior): LogNormalPrior()\n",
       "        (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "      )\n",
       "    )\n",
       "    (mean_module): ZeroMean()\n",
       "    (covar_module): ScaleKernel(\n",
       "      (base_kernel): MaternKernel(\n",
       "        (raw_lengthscale_constraint): Positive()\n",
       "      )\n",
       "      (raw_outputscale_constraint): Positive()\n",
       "    )\n",
       "  )\n",
       "  (mll): ExactMarginalLogLikelihood(\n",
       "    (likelihood): GaussianLikelihood(\n",
       "      (noise_covar): HomoskedasticNoise(\n",
       "        (noise_prior): LogNormalPrior()\n",
       "        (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "      )\n",
       "    )\n",
       "    (model): ExactGPLayer(\n",
       "      (likelihood): GaussianLikelihood(\n",
       "        (noise_covar): HomoskedasticNoise(\n",
       "          (noise_prior): LogNormalPrior()\n",
       "          (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "        )\n",
       "      )\n",
       "      (mean_module): ZeroMean()\n",
       "      (covar_module): ScaleKernel(\n",
       "        (base_kernel): MaternKernel(\n",
       "          (raw_lengthscale_constraint): Positive()\n",
       "        )\n",
       "        (raw_outputscale_constraint): Positive()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_weights_file = \"../../outputs/FSMol_ADKTModel_gnn+ecfp+fc_2022-03-22_15-28-36/best_validation.pt\"\n",
    "\n",
    "adkt_model = ADKTModelFeatureExtractor.build_from_model_file(\n",
    "    model_weights_file,\n",
    "    device=device\n",
    ").to(device)\n",
    "\n",
    "adkt_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5206bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "representations = []\n",
    "\n",
    "for features in dkt_batches:\n",
    "    representation = adkt_model.get_representation(features)\n",
    "    representations.append(representation)\n",
    "    \n",
    "del adkt_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34d6a02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = task.samples\n",
    "\n",
    "x_all = torch.cat(representations, dim=0)\n",
    "y_all = torch.FloatTensor([float(x.numeric_label) for x in dataset]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7406af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_init_points = 16\n",
    "query_batch_size = 1\n",
    "num_bo_iters = 20\n",
    "kernel_type = \"matern\"\n",
    "init_from = 1600\n",
    "noise_init = 0.01\n",
    "noise_prior = True\n",
    "\n",
    "num_repeats = 20\n",
    "\n",
    "bo_records = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fc4efa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 20/20 [26:32<00:00, 79.63s/it]\n"
     ]
    }
   ],
   "source": [
    "for repeat in tqdm(range(num_repeats)):\n",
    "    bo_record = run_gp_ei_bo(dataset, x_all, y_all, num_init_points, query_batch_size, num_bo_iters, kernel_type, device, init_from, noise_init, noise_prior)\n",
    "    bo_records.append(min_so_far(bo_record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4752fcaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb160073c10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_axis = np.arange(query_batch_size*num_bo_iters+1)\n",
    "\n",
    "bo_records = np.array([[y_all[i].item() for i in bo_record] for bo_record in bo_records])\n",
    "bo_records_mean = bo_records.mean(axis=0)\n",
    "bo_records_std = bo_records.std(axis=0)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "plt.plot(x_axis, bo_records_mean, label=\"ADKT\")\n",
    "plt.fill_between(x_axis, bo_records_mean-bo_records_std, bo_records_mean+bo_records_std, alpha=0.4)\n",
    "\n",
    "plt.xlabel(\"Number of molecules queried\")\n",
    "plt.ylabel(\"Top-1 relative growth\")\n",
    "plt.ylim(0, 1.5)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac81272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"outputs/adkt_bo_records.pkl\", \"wb\") as output_file:\n",
    "    pickle.dump(bo_records, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b5fd57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
