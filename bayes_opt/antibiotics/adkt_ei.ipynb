{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c583b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pyprojroot import here as project_root\n",
    "\n",
    "sys.path.insert(0, str(project_root()))\n",
    "\n",
    "from fs_mol.data.dkt import get_dkt_batcher\n",
    "from fs_mol.utils.torch_utils import torchify\n",
    "\n",
    "from bayes_opt.bo_utils import load_antibiotics_dataset, run_gp_ei_bo, min_so_far, task_to_batches, ADKTModelFeatureExtractor\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b7123ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping datapoint O=C([O-])C=CC(=O)[O-].[Fe+2], cannot featurise with current metadata.\n",
      "Skipping datapoint CC(O)CN1CCN(CC(=O)[O-])CCN(CC(=O)[O-])CCN(CC(=O)[O-])CC1.[Gd+3], cannot featurise with current metadata.\n"
     ]
    }
   ],
   "source": [
    "task = load_antibiotics_dataset(\"antibiotics-dataset.xlsx\", \"../../fs_mol/preprocessing/utils/helper_files/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ac1070b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batcher = get_dkt_batcher(max_num_graphs=100)\n",
    "dkt_batches = torchify(\n",
    "    task_to_batches(task, batcher), \n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a342b4f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ADKTModelFeatureExtractor(\n",
       "  (graph_feature_extractor): GraphFeatureExtractor(\n",
       "    (init_node_proj): Linear(in_features=32, out_features=128, bias=False)\n",
       "    (gnn): GNN(\n",
       "      (gnn_blocks): ModuleList(\n",
       "        (0): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (6): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (7): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (8): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (9): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (readout): CombinedGraphReadout(\n",
       "      (_weighted_mean_pooler): MultiHeadWeightedGraphReadout(\n",
       "        (_scoring_module): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=12, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_transformation_mlp): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_combination_layer): Linear(in_features=768, out_features=512, bias=False)\n",
       "      )\n",
       "      (_weighted_sum_pooler): MultiHeadWeightedGraphReadout(\n",
       "        (_scoring_module): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=12, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_transformation_mlp): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_combination_layer): Linear(in_features=768, out_features=512, bias=False)\n",
       "      )\n",
       "      (_max_pooler): UnweightedGraphReadout(\n",
       "        (_combination_layer): Linear(in_features=1408, out_features=512, bias=False)\n",
       "      )\n",
       "      (_combination_layer): Linear(in_features=1536, out_features=512, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2560, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  )\n",
       "  (gp_likelihood): GaussianLikelihood(\n",
       "    (noise_covar): HomoskedasticNoise(\n",
       "      (noise_prior): LogNormalPrior()\n",
       "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "    )\n",
       "  )\n",
       "  (gp_model): ExactGPLayer(\n",
       "    (likelihood): GaussianLikelihood(\n",
       "      (noise_covar): HomoskedasticNoise(\n",
       "        (noise_prior): LogNormalPrior()\n",
       "        (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "      )\n",
       "    )\n",
       "    (mean_module): ZeroMean()\n",
       "    (covar_module): ScaleKernel(\n",
       "      (base_kernel): MaternKernel(\n",
       "        (raw_lengthscale_constraint): Positive()\n",
       "      )\n",
       "      (raw_outputscale_constraint): Positive()\n",
       "    )\n",
       "  )\n",
       "  (mll): ExactMarginalLogLikelihood(\n",
       "    (likelihood): GaussianLikelihood(\n",
       "      (noise_covar): HomoskedasticNoise(\n",
       "        (noise_prior): LogNormalPrior()\n",
       "        (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "      )\n",
       "    )\n",
       "    (model): ExactGPLayer(\n",
       "      (likelihood): GaussianLikelihood(\n",
       "        (noise_covar): HomoskedasticNoise(\n",
       "          (noise_prior): LogNormalPrior()\n",
       "          (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "        )\n",
       "      )\n",
       "      (mean_module): ZeroMean()\n",
       "      (covar_module): ScaleKernel(\n",
       "        (base_kernel): MaternKernel(\n",
       "          (raw_lengthscale_constraint): Positive()\n",
       "        )\n",
       "        (raw_outputscale_constraint): Positive()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_weights_file = \"../../outputs/FSMol_ADKTModel_gnn+ecfp+fc_2022-03-22_15-28-36/best_validation.pt\"\n",
    "\n",
    "adkt_model = ADKTModelFeatureExtractor.build_from_model_file(\n",
    "    model_weights_file,\n",
    "    device=device\n",
    ").to(device)\n",
    "\n",
    "adkt_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5206bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "representations = []\n",
    "\n",
    "for features in dkt_batches:\n",
    "    representation = adkt_model.get_representation(features)\n",
    "    representations.append(representation)\n",
    "    \n",
    "del adkt_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34d6a02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = task.samples\n",
    "\n",
    "x_all = torch.cat(representations, dim=0)\n",
    "y_all = torch.FloatTensor([float(x.numeric_label) for x in dataset]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7406af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_init_points = 16\n",
    "query_batch_size = 1\n",
    "num_bo_iters = 20\n",
    "kernel_type = \"matern\"\n",
    "init_from = 2000\n",
    "noise_init = 0.01\n",
    "noise_prior = True\n",
    "\n",
    "num_repeats = 20\n",
    "\n",
    "bo_records = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fc4efa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [26:21<00:00, 79.05s/it]\n"
     ]
    }
   ],
   "source": [
    "for repeat in tqdm(range(num_repeats)):\n",
    "    bo_record = run_gp_ei_bo(dataset, x_all, y_all, num_init_points, query_batch_size, num_bo_iters, kernel_type, device, init_from, noise_init, noise_prior)\n",
    "    bo_records.append(min_so_far(bo_record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4752fcaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fefb456a450>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_axis = np.arange(query_batch_size*num_bo_iters+1)\n",
    "\n",
    "bo_records = np.array([[y_all[i].item() for i in bo_record] for bo_record in bo_records])\n",
    "bo_records_mean = bo_records.mean(axis=0)\n",
    "bo_records_std = bo_records.std(axis=0)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "plt.plot(x_axis, bo_records_mean, label=\"ADKT\")\n",
    "plt.fill_between(x_axis, bo_records_mean-bo_records_std, bo_records_mean+bo_records_std, alpha=0.4)\n",
    "\n",
    "plt.xlabel(\"Number of molecules queried\")\n",
    "plt.ylabel(\"Top-1 relative growth\")\n",
    "plt.ylim(0, 1.5)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac81272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"outputs/adkt_bo_records.pkl\", \"wb\") as output_file:\n",
    "    pickle.dump(bo_records, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b5fd57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
