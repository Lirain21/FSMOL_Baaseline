{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c583b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pyprojroot import here as project_root\n",
    "\n",
    "sys.path.insert(0, str(project_root()))\n",
    "\n",
    "from fs_mol.data.dkt import get_dkt_batcher\n",
    "from fs_mol.utils.torch_utils import torchify\n",
    "\n",
    "from bayes_opt.bo_utils import load_antibiotics_dataset, run_gp_ei_bo, min_so_far, task_to_batches, DKTModelFeatureExtractor\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b7123ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping datapoint O=C([O-])C=CC(=O)[O-].[Fe+2], cannot featurise with current metadata.\n",
      "Skipping datapoint CC(O)CN1CCN(CC(=O)[O-])CCN(CC(=O)[O-])CCN(CC(=O)[O-])CC1.[Gd+3], cannot featurise with current metadata.\n"
     ]
    }
   ],
   "source": [
    "task = load_antibiotics_dataset(\"antibiotics-dataset.xlsx\", \"../../fs_mol/preprocessing/utils/helper_files/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eec150c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batcher = get_dkt_batcher(max_num_graphs=100)\n",
    "dkt_batches = torchify(\n",
    "    task_to_batches(task, batcher), \n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "532dfce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DKTModelFeatureExtractor(\n",
       "  (graph_feature_extractor): GraphFeatureExtractor(\n",
       "    (init_node_proj): Linear(in_features=32, out_features=128, bias=False)\n",
       "    (gnn): GNN(\n",
       "      (gnn_blocks): ModuleList(\n",
       "        (0): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (6): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (7): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (8): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (9): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (readout): CombinedGraphReadout(\n",
       "      (_weighted_mean_pooler): MultiHeadWeightedGraphReadout(\n",
       "        (_scoring_module): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=12, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_transformation_mlp): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_combination_layer): Linear(in_features=768, out_features=512, bias=False)\n",
       "      )\n",
       "      (_weighted_sum_pooler): MultiHeadWeightedGraphReadout(\n",
       "        (_scoring_module): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=12, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_transformation_mlp): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_combination_layer): Linear(in_features=768, out_features=512, bias=False)\n",
       "      )\n",
       "      (_max_pooler): UnweightedGraphReadout(\n",
       "        (_combination_layer): Linear(in_features=1408, out_features=512, bias=False)\n",
       "      )\n",
       "      (_combination_layer): Linear(in_features=1536, out_features=512, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2560, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  )\n",
       "  (gp_likelihood): GaussianLikelihood(\n",
       "    (noise_covar): HomoskedasticNoise(\n",
       "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "    )\n",
       "  )\n",
       "  (gp_model): ExactGPLayer(\n",
       "    (likelihood): GaussianLikelihood(\n",
       "      (noise_covar): HomoskedasticNoise(\n",
       "        (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "      )\n",
       "    )\n",
       "    (mean_module): ZeroMean()\n",
       "    (covar_module): ScaleKernel(\n",
       "      (base_kernel): MaternKernel(\n",
       "        (raw_lengthscale_constraint): Positive()\n",
       "      )\n",
       "      (raw_outputscale_constraint): Positive()\n",
       "    )\n",
       "  )\n",
       "  (mll): ExactMarginalLogLikelihood(\n",
       "    (likelihood): GaussianLikelihood(\n",
       "      (noise_covar): HomoskedasticNoise(\n",
       "        (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "      )\n",
       "    )\n",
       "    (model): ExactGPLayer(\n",
       "      (likelihood): GaussianLikelihood(\n",
       "        (noise_covar): HomoskedasticNoise(\n",
       "          (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "        )\n",
       "      )\n",
       "      (mean_module): ZeroMean()\n",
       "      (covar_module): ScaleKernel(\n",
       "        (base_kernel): MaternKernel(\n",
       "          (raw_lengthscale_constraint): Positive()\n",
       "        )\n",
       "        (raw_outputscale_constraint): Positive()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_weights_file = \"../../outputs/FSMol_DKTModel_gnn+ecfp+fc_2022-02-15_02-11-49/best_validation.pt\"\n",
    "\n",
    "dkt_model = DKTModelFeatureExtractor.build_from_model_file(\n",
    "    model_weights_file,\n",
    "    device=device\n",
    ").to(device)\n",
    "\n",
    "dkt_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8645752d",
   "metadata": {},
   "outputs": [],
   "source": [
    "representations = []\n",
    "\n",
    "for features in dkt_batches:\n",
    "    representation = dkt_model.get_representation(features)\n",
    "    representations.append(representation)\n",
    "    \n",
    "del dkt_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90211d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = task.samples\n",
    "\n",
    "x_all = torch.cat(representations, dim=0)\n",
    "y_all = torch.FloatTensor([float(x.numeric_label) for x in dataset]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7406af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_init_points = 16\n",
    "query_batch_size = 1\n",
    "num_bo_iters = 20\n",
    "kernel_type = \"matern\"\n",
    "init_from = 2000\n",
    "noise_init = 0.01\n",
    "noise_prior = True\n",
    "\n",
    "num_repeats = 20\n",
    "\n",
    "bo_records = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fc4efa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [26:25<00:00, 79.27s/it]\n"
     ]
    }
   ],
   "source": [
    "for repeat in tqdm(range(num_repeats)):\n",
    "    bo_record = run_gp_ei_bo(dataset, x_all, y_all, num_init_points, query_batch_size, num_bo_iters, kernel_type, device, init_from, noise_init, noise_prior)\n",
    "    bo_records.append(min_so_far(bo_record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4752fcaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f3e5c067fd0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_axis = np.arange(query_batch_size*num_bo_iters+1)\n",
    "\n",
    "bo_records = np.array([[y_all[i].item() for i in bo_record] for bo_record in bo_records])\n",
    "bo_records_mean = bo_records.mean(axis=0)\n",
    "bo_records_std = bo_records.std(axis=0)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "plt.plot(x_axis, bo_records_mean, label=\"DKT\")\n",
    "plt.fill_between(x_axis, bo_records_mean-bo_records_std, bo_records_mean+bo_records_std, alpha=0.4)\n",
    "\n",
    "plt.xlabel(\"Number of molecules queried\")\n",
    "plt.ylabel(\"Top-1 relative growth\")\n",
    "plt.ylim(0, 1.5)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac81272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"outputs/dkt_bo_records.pkl\", \"wb\") as output_file:\n",
    "    pickle.dump(bo_records, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6b7680",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
