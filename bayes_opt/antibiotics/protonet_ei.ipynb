{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c583b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pyprojroot import here as project_root\n",
    "\n",
    "sys.path.insert(0, str(project_root()))\n",
    "\n",
    "from fs_mol.data.dkt import get_dkt_batcher\n",
    "from fs_mol.utils.torch_utils import torchify\n",
    "\n",
    "from bayes_opt.bo_utils import load_antibiotics_dataset, run_gp_ei_bo, min_so_far, task_to_batches, PrototypicalNetworkFeatureExtractor\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b7123ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping datapoint O=C([O-])C=CC(=O)[O-].[Fe+2], cannot featurise with current metadata.\n",
      "Skipping datapoint CC(O)CN1CCN(CC(=O)[O-])CCN(CC(=O)[O-])CCN(CC(=O)[O-])CC1.[Gd+3], cannot featurise with current metadata.\n"
     ]
    }
   ],
   "source": [
    "task = load_antibiotics_dataset(\"antibiotics-dataset.xlsx\", \"../../fs_mol/preprocessing/utils/helper_files/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eec150c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batcher = get_dkt_batcher(max_num_graphs=100)\n",
    "dkt_batches = torchify(\n",
    "    task_to_batches(task, batcher), \n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "532dfce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PrototypicalNetworkFeatureExtractor(\n",
       "  (graph_feature_extractor): GraphFeatureExtractor(\n",
       "    (init_node_proj): Linear(in_features=32, out_features=128, bias=False)\n",
       "    (gnn): GNN(\n",
       "      (gnn_blocks): ModuleList(\n",
       "        (0): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (6): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (7): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (8): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (9): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (readout): CombinedGraphReadout(\n",
       "      (_weighted_mean_pooler): MultiHeadWeightedGraphReadout(\n",
       "        (_scoring_module): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=12, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_transformation_mlp): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_combination_layer): Linear(in_features=768, out_features=512, bias=False)\n",
       "      )\n",
       "      (_weighted_sum_pooler): MultiHeadWeightedGraphReadout(\n",
       "        (_scoring_module): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=12, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_transformation_mlp): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_combination_layer): Linear(in_features=768, out_features=512, bias=False)\n",
       "      )\n",
       "      (_max_pooler): UnweightedGraphReadout(\n",
       "        (_combination_layer): Linear(in_features=1408, out_features=512, bias=False)\n",
       "      )\n",
       "      (_combination_layer): Linear(in_features=1536, out_features=512, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2560, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_weights_file = \"../../../fs-mol-checkpoints/PNSupport64_best_validation.pt\"\n",
    "\n",
    "protonet_model = PrototypicalNetworkFeatureExtractor.build_from_model_file(\n",
    "    model_weights_file,\n",
    "    device=device\n",
    ").to(device)\n",
    "\n",
    "protonet_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8645752d",
   "metadata": {},
   "outputs": [],
   "source": [
    "representations = []\n",
    "\n",
    "for features in dkt_batches:\n",
    "    representation = protonet_model.get_representation(features)\n",
    "    representations.append(representation)\n",
    "    \n",
    "del protonet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90211d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = task.samples\n",
    "\n",
    "x_all = torch.cat(representations, dim=0)\n",
    "y_all = torch.FloatTensor([float(x.numeric_label) for x in dataset]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7406af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_init_points = 16\n",
    "query_batch_size = 1\n",
    "num_bo_iters = 20\n",
    "kernel_type = \"matern\"\n",
    "init_from = 1600\n",
    "noise_init = 0.01\n",
    "noise_prior = True\n",
    "\n",
    "num_repeats = 20\n",
    "\n",
    "bo_records = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fc4efa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 20/20 [26:43<00:00, 80.18s/it]\n"
     ]
    }
   ],
   "source": [
    "for repeat in tqdm(range(num_repeats)):\n",
    "    bo_record = run_gp_ei_bo(dataset, x_all, y_all, num_init_points, query_batch_size, num_bo_iters, kernel_type, device, init_from, noise_init, noise_prior)\n",
    "    bo_records.append(min_so_far(bo_record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4752fcaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f59f83aaf50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_axis = np.arange(query_batch_size*num_bo_iters+1)\n",
    "\n",
    "bo_records = np.array([[y_all[i].item() for i in bo_record] for bo_record in bo_records])\n",
    "bo_records_mean = bo_records.mean(axis=0)\n",
    "bo_records_std = bo_records.std(axis=0)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "plt.plot(x_axis, bo_records_mean, label=\"ProtoNet\")\n",
    "plt.fill_between(x_axis, bo_records_mean-bo_records_std, bo_records_mean+bo_records_std, alpha=0.4)\n",
    "\n",
    "plt.xlabel(\"Number of molecules queried\")\n",
    "plt.ylabel(\"Top-1 relative growth\")\n",
    "plt.ylim(0, 1.5)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac81272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"outputs/protonet_bo_records.pkl\", \"wb\") as output_file:\n",
    "    pickle.dump(bo_records, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33b7f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
