{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c583b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pyprojroot import here as project_root\n",
    "\n",
    "sys.path.insert(0, str(project_root()))\n",
    "\n",
    "from fs_mol.data.cnp import get_cnp_batcher\n",
    "from fs_mol.utils.torch_utils import torchify\n",
    "\n",
    "from bayes_opt.bo_utils import load_antibiotics_dataset, run_gp_ei_bo, min_so_far, task_to_batches, CNPModelFeatureExtractor\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b7123ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping datapoint O=C([O-])C=CC(=O)[O-].[Fe+2], cannot featurise with current metadata.\n",
      "Skipping datapoint CC(O)CN1CCN(CC(=O)[O-])CCN(CC(=O)[O-])CCN(CC(=O)[O-])CC1.[Gd+3], cannot featurise with current metadata.\n"
     ]
    }
   ],
   "source": [
    "task = load_antibiotics_dataset(\"antibiotics-dataset.xlsx\", \"../../fs_mol/preprocessing/utils/helper_files/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ac1070b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batcher = get_cnp_batcher(max_num_graphs=100)\n",
    "cnp_batches = torchify(\n",
    "    task_to_batches(task, batcher), \n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a342b4f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNPModelFeatureExtractor(\n",
       "  (graph_feature_extractor): GraphFeatureExtractor(\n",
       "    (init_node_proj): Linear(in_features=32, out_features=128, bias=False)\n",
       "    (gnn): GNN(\n",
       "      (gnn_blocks): ModuleList(\n",
       "        (0): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (6): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (7): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (8): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (9): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (readout): CombinedGraphReadout(\n",
       "      (_weighted_mean_pooler): MultiHeadWeightedGraphReadout(\n",
       "        (_scoring_module): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=12, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_transformation_mlp): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_combination_layer): Linear(in_features=768, out_features=512, bias=False)\n",
       "      )\n",
       "      (_weighted_sum_pooler): MultiHeadWeightedGraphReadout(\n",
       "        (_scoring_module): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=12, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_transformation_mlp): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_combination_layer): Linear(in_features=768, out_features=512, bias=False)\n",
       "      )\n",
       "      (_max_pooler): UnweightedGraphReadout(\n",
       "        (_combination_layer): Linear(in_features=1408, out_features=512, bias=False)\n",
       "      )\n",
       "      (_combination_layer): Linear(in_features=1536, out_features=512, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2560, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  )\n",
       "  (encoder_label_fc): Sequential(\n",
       "    (0): Linear(in_features=1, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  )\n",
       "  (encoder_final_fc): Sequential(\n",
       "    (0): Linear(in_features=576, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       "  (decoder_fc): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=256, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model_weights_file = \"../../outputs/FSMol_CNPModel_gnn+ecfp+fc_2022-04-11_16-46-27/best_validation.pt\" # classification\n",
    "model_weights_file = \"../../outputs/FSMol_CNPModel_gnn+ecfp+fc_2022-03-18_02-30-04/best_validation.pt\" # regression\n",
    "\n",
    "cnp_model = CNPModelFeatureExtractor.build_from_model_file(\n",
    "    model_weights_file,\n",
    "    device=device\n",
    ").to(device)\n",
    "\n",
    "cnp_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5206bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "representations = []\n",
    "\n",
    "for features in cnp_batches:\n",
    "    representation = cnp_model.get_representation(features)\n",
    "    representations.append(representation)\n",
    "    \n",
    "del cnp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34d6a02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = task.samples\n",
    "\n",
    "x_all = torch.cat(representations, dim=0)\n",
    "y_all = torch.FloatTensor([float(x.numeric_label) for x in dataset]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7406af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_init_points = 16\n",
    "query_batch_size = 1\n",
    "num_bo_iters = 20\n",
    "kernel_type = \"matern\"\n",
    "init_from = 1600\n",
    "noise_init = 0.01\n",
    "noise_prior = True\n",
    "\n",
    "num_repeats = 20\n",
    "\n",
    "bo_records = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fc4efa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 20/20 [26:56<00:00, 80.85s/it]\n"
     ]
    }
   ],
   "source": [
    "for repeat in tqdm(range(num_repeats)):\n",
    "    bo_record = run_gp_ei_bo(dataset, x_all, y_all, num_init_points, query_batch_size, num_bo_iters, kernel_type, device, init_from, noise_init, noise_prior)\n",
    "    bo_records.append(min_so_far(bo_record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4752fcaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_axis = np.arange(query_batch_size*num_bo_iters+1)\n",
    "\n",
    "bo_records = np.array([[y_all[i].item() for i in bo_record] for bo_record in bo_records])\n",
    "bo_records_mean = bo_records.mean(axis=0)\n",
    "bo_records_std = bo_records.std(axis=0)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "plt.plot(x_axis, bo_records_mean)\n",
    "plt.fill_between(x_axis, bo_records_mean-bo_records_std, bo_records_mean+bo_records_std, alpha=0.4)\n",
    "\n",
    "plt.xlabel(\"Number of molecules queried\")\n",
    "plt.ylabel(\"Top-1 relative growth\")\n",
    "plt.ylim(0, 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac81272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"outputs/cnp_bo_records.pkl\", \"wb\") as output_file:\n",
    "    pickle.dump(bo_records, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b5fd57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
