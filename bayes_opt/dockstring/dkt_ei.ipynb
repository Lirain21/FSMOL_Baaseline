{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c583b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pyprojroot import here as project_root\n",
    "\n",
    "sys.path.insert(0, str(project_root()))\n",
    "\n",
    "from fs_mol.data.dkt import get_dkt_batcher\n",
    "from fs_mol.utils.torch_utils import torchify\n",
    "\n",
    "from bayes_opt.bo_utils import load_dockstring_dataset, run_gp_ei_bo, min_so_far, task_to_batches, DKTModelFeatureExtractor\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b7123ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = load_dockstring_dataset(\"dockstring-dataset-subsampled.csv\", \"../../fs_mol/preprocessing/utils/helper_files/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eec150c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batcher = get_dkt_batcher(max_num_graphs=100)\n",
    "dkt_batches = torchify(\n",
    "    task_to_batches(task, batcher), \n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "532dfce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DKTModelFeatureExtractor(\n",
       "  (graph_feature_extractor): GraphFeatureExtractor(\n",
       "    (init_node_proj): Linear(in_features=32, out_features=128, bias=False)\n",
       "    (gnn): GNN(\n",
       "      (gnn_blocks): ModuleList(\n",
       "        (0): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (6): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (7): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (8): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (9): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (readout): CombinedGraphReadout(\n",
       "      (_weighted_mean_pooler): MultiHeadWeightedGraphReadout(\n",
       "        (_scoring_module): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=12, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_transformation_mlp): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_combination_layer): Linear(in_features=768, out_features=512, bias=False)\n",
       "      )\n",
       "      (_weighted_sum_pooler): MultiHeadWeightedGraphReadout(\n",
       "        (_scoring_module): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=12, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_transformation_mlp): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_combination_layer): Linear(in_features=768, out_features=512, bias=False)\n",
       "      )\n",
       "      (_max_pooler): UnweightedGraphReadout(\n",
       "        (_combination_layer): Linear(in_features=1408, out_features=512, bias=False)\n",
       "      )\n",
       "      (_combination_layer): Linear(in_features=1536, out_features=512, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2560, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  )\n",
       "  (gp_likelihood): GaussianLikelihood(\n",
       "    (noise_covar): HomoskedasticNoise(\n",
       "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "    )\n",
       "  )\n",
       "  (gp_model): ExactGPLayer(\n",
       "    (likelihood): GaussianLikelihood(\n",
       "      (noise_covar): HomoskedasticNoise(\n",
       "        (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "      )\n",
       "    )\n",
       "    (mean_module): ZeroMean()\n",
       "    (covar_module): ScaleKernel(\n",
       "      (base_kernel): MaternKernel(\n",
       "        (raw_lengthscale_constraint): Positive()\n",
       "      )\n",
       "      (raw_outputscale_constraint): Positive()\n",
       "    )\n",
       "  )\n",
       "  (mll): ExactMarginalLogLikelihood(\n",
       "    (likelihood): GaussianLikelihood(\n",
       "      (noise_covar): HomoskedasticNoise(\n",
       "        (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "      )\n",
       "    )\n",
       "    (model): ExactGPLayer(\n",
       "      (likelihood): GaussianLikelihood(\n",
       "        (noise_covar): HomoskedasticNoise(\n",
       "          (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "        )\n",
       "      )\n",
       "      (mean_module): ZeroMean()\n",
       "      (covar_module): ScaleKernel(\n",
       "        (base_kernel): MaternKernel(\n",
       "          (raw_lengthscale_constraint): Positive()\n",
       "        )\n",
       "        (raw_outputscale_constraint): Positive()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_weights_file = \"../../outputs/FSMol_DKTModel_gnn+ecfp+fc_2022-02-15_02-11-49/best_validation.pt\"\n",
    "\n",
    "dkt_model = DKTModelFeatureExtractor.build_from_model_file(\n",
    "    model_weights_file,\n",
    "    device=device\n",
    ").to(device)\n",
    "\n",
    "dkt_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8645752d",
   "metadata": {},
   "outputs": [],
   "source": [
    "representations = []\n",
    "\n",
    "for features in dkt_batches:\n",
    "    representation = dkt_model.get_representation(features)\n",
    "    representations.append(representation)\n",
    "    \n",
    "del dkt_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90211d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = task.samples\n",
    "\n",
    "x_all = torch.cat(representations, dim=0)\n",
    "y_all = torch.FloatTensor([float(x.numeric_label) for x in dataset]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7406af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_init_points = 16\n",
    "query_batch_size = 1\n",
    "num_bo_iters = 20\n",
    "kernel_type = \"matern\"\n",
    "init_from = 1600\n",
    "noise_init = 0.01\n",
    "noise_prior = True\n",
    "\n",
    "num_repeats = 20\n",
    "\n",
    "bo_records = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fc4efa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 20/20 [26:16<00:00, 78.80s/it]\n"
     ]
    }
   ],
   "source": [
    "for repeat in tqdm(range(num_repeats)):\n",
    "    bo_record = run_gp_ei_bo(dataset, x_all, y_all, num_init_points, query_batch_size, num_bo_iters, kernel_type, device, init_from, noise_init, noise_prior)\n",
    "    bo_records.append(min_so_far(bo_record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4752fcaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fc8639f8ad0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU8AAAE9CAYAAACLJ+A4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAA2LklEQVR4nO3deXRkV33g8e+v9lJVqbSUpF7Uu7de3G7TjYkBBzDGgYyDgYQJJDMQyMSBcVg8h2RMyDCGHOYEGCYDhAAeQhImIawxNmZY4g1jwEu3affqdu9utVr7vpRKVXXnj/dKXS1VlWp5pVKrfp9zdFT11vtU0k/3vnvv74kxBqWUUqVx1boASil1OdLgqZRSZdDgqZRSZdDgqZRSZdDgqZRSZdDgqZRSZfDUugBOiMViZuPGjbUuhlJqhdm3b9+AMaYt17oVETw3btzI3r17a10MpdQKIyJn863TZrtSSpVh2dU8ReSbwNX22yZgxBizq2YFUkqpHJZd8DTG/G7mtYh8BhitYXGUUiqnZRc8M0REgH8P3Fzrsii10s3OztLV1UU8Hq91UWoiEAjQ2dmJ1+step9lGzyBm4BeY8zxWhdEqZWuq6uLSCTCxo0bseot9cMYw+DgIF1dXWzatKno/WrSYSQiD4nIoRxft2dt9nbgXwoc4w4R2Ssie/v7+6tfaKVWsHg8Tmtra90FTgARobW1teRad01qnsaYWwqtFxEP8BZgd4Fj3AvcC7Bnzx7Nq6dUheoxcGaUc+3LdajSLcDzxpiuWhdEKbU0ent7+b3f+z02b97M7t27ufHGG7nvvvt47LHHiEajXH/99WzdupWPfexjOff/6le/yrXXXsvOnTvZsWMH999/P3feeSe7du1i27ZtBINBdu3axa5du/jOd75TcXmX6z3Pt1Ggya6UWlmMMbzpTW/ine98J1//+tcBOHv2LA888ADNzc3cdNNNPPjgg0xOTrJr1y5uu+02du++2DDt6uriE5/4BM8++yzRaJSJiQn6+/u5/XbrTuCZM2e47bbb2L9/v2NlXpY1T2PMHxhjvlTrciillsYjjzyCz+fjPe95z9yyDRs28L73ve+S7UKhELt37+bkyZOXLO/r6yMSiRAOhwEIh8Mldf6UY1kGz+VmdHqWI91jtS6GUivW4cOHeclLXrLodoODgzz55JNs3779kuXXXXcdHR0dbNq0iXe96118//vfr1ZR5yzXZnvNpdOGruFpjveN0zs2A0DI72ZDa6jGJVOquj72/cOOVxa2rWnkv//W9sU3tN1555088cQT+Hw+Pv3pT/Ozn/2M66+/HpfLxd13370geLrdbn70ox/xzDPP8PDDD3PXXXexb98+7rnnHkevI5sGz3kmZ5Kc6Jvg1MAE04n0Jev2nxthbVMQj1sr7Eo5afv27Xz3u9+de/+FL3yBgYEB9uzZAzB3zzMjlUrN3fN84xvfyMc//nFEhBtuuIEbbriB173udbzrXe/S4LkUukemOd43QffINPkeKDo5k+L5nnF2rI0ubeGUWkKl1BCdcvPNN/Pnf/7nfPGLX+S9730vAFNTU3m3d7vdl3T+dHd309PTM9f0379/Pxs2bKhqmes6eMZnU5zqn+RE/wQT8WRR+xzpHmNzW4gGX13/6JRylIjwve99j7vuuotPfepTtLW1EQqF+OQnP1nU/rOzs3zoQx+iu7ubQCBAW1sbX/pSdfucZSU8t33Pnj2m1Hyevzg5wLmhKVLpxbedb2OsgZdviZW+o1LL1NGjR9m6dWuti1FTuX4GIrLPGLMn1/Z1e/PuzEB5gTOz78DEjLMFUkpdVuoyeH7+4eM88Nx5njw1yOmBSSZnimuyZ9t3drgKJVNKXS7q8sbdqYFJfvXiCDPJi1XPkN9DR8RPe2OAjkY/7RHre757m4MTCc4MTLIxpkOXlKpHdRk8//p3d7FnQzOj07P0jc/QOxanb2yG3vE4z744TCIrqEb8Htob/axqDPDKK9uIBi/m+9t/boTOZh26pFYGY0zdJgcpp++nLoMnQIPfjYjQ1ODjqo7I3HJjDKPTs/SOzdA3Hp/7/ouTg3jcLn5j+6q5bacSKY5cGGNnZ1MNrkAp5wQCAQYHB+syLV0mn2cgEChpv7oNnq/fvppfnByYmz2UkQmoTQ0+rl51Mah++acnOdU/seA4z18YZ0tbmJC/bn+UagXo7Oykq6uLes2Nm8kkX4q6/YsP+tzcfE07h86Pcah7NO/A+IxNbSEef6GfmdkUfq97bnkybdh/boRXXKFDl9Tly+v1Vj2RxkpT1zfrRIRrO6PcfE07QV/hH8XmWJi0gbNDC2c9nB2com+8Pp/9olS9quvgmdHRGOANO1azKurPu836lgbcIjmb7gDPnh2pUumUUsuRBk9bwOvmNVe3s7MzSq775T6Pi3UtQU4NTObcf2gykTewKqVWHg2eWUSEHWujvDZPM35TLEz3yDTx2VTO/Z/rGmG23GlLSqnLigbPHNrtZvzq6KVDFza3haz7noO5a5/TibQmTVaqTmjwzCPgdfOaa9q5bl0Ul92MX9/SgNslnOrPHTwBnu8ZY6KM6Z5KqcuLBs9FbF8T5eat7TT43HjdLtY1N+S97wmQSsP+F0eWroBKqZrQ4FmE9kiAG7e0AlbTvdB9T4AXh6boG9OhS0qtZBo8i5SZ0745FsIAZwrUPsHKurQScqUqpXLT4FmkgNdtD1dqwOOSgk13gOGpWZ48NcQLveOcG5picGKG6URKA6pSK0TdTs8sRzToJZFMs66lgVMDi4/pPD0wyel5QdYlViAO+tw02F9Br2fudSzsx+Wqr8QMSl2ONHiWoDHgoX98hs1tIR452sd0IkXQ5158xyxpY2VjmkqkGMyx/qYrY6xraXCmwEqpqtFmewmiDZn7nmHrvmee8Z6VOKmzlJS6LGjwLEFjwAqe65qD1n3PKgS6C6NxphP5e/KVUsuDBs8SZHrcPW4X61sLj/cslzFa+1TqcqDBswQhvweP3ZmzORamZzTOVML52UTVCMpKKWdp8CxRY9DqYyt2vGc5JuJJenWQvVLLmgbPEjXaTffOliBe9+LjPculTXelljcNniXKdBp5XC42tIQKJgmpRNfQ9CVP8VRKLS8aPEuU/ejhTW0hesbiTFUhi1IybfKmvlNK1Z4GzxI1ZgXPzbEQUL0OHm26K7V8afAsUcTvmcvvubbZuu85fwqmU4YmZxmeTFTl2EqpymjwLJHLJUSy7ntubA0VNc+9XNU8tlKqfBo8y3DJfc9YiN6xmapljz89MEUqrZmYlFpuNHiWITPWE2BzWxigak33RDLNuRzPildK1ZYGzzJkhisBrG0K4nO7OK1Nd6XqyrILniKyS0SeFJH9IrJXRG6odZnmy262u13CxlhD1cZ7AvSMVu+2gFKqPMsueAKfAj5mjNkFfNR+v6w0Br1IVr7iTbEwfePVDXDVyOCklCrfcgyeBmi0X0eB7hqWJSe3Swj5s+572uM9q3XfM3NsfYSHUsvHcgyeHwQ+LSLngP8JfDjXRiJyh92s39vf37+U5QOsrPIZa5qC+D2uqtYOJ2dSXBjVZCFKLRc1CZ4i8pCIHMrxdTvwXuAuY8w64C7g73IdwxhzrzFmjzFmT1tb21IWH8hx37M1VPVUctW8r6qUKk1NnmFkjLkl3zoR+RrwAfvtt4GvLEmhSpQ9TROs8Z7HDo8zHp+dG0TvtK7hKeKzKQLe0p6bpJRy3nJstncDr7Jf3wwcr2FZ8orOC56b26p/3zNtqvPcJKVU6ZZj8Pwj4DMi8hzwP4A7alyenBrn1S5XRzP3Pasb3E72afBUajlYdo8eNsY8AeyudTkW4/O4CPpcTCesnJtLdd9zdHqWgYkZYmF/Vc+jlCpsOdY8Lxu5mu4DEzOMTc9W9bwn+3TMp1K1psGzAguCZ6y689wzzg5NkUxplnmlakmDZwUW3PdsChDwuqo+Fz2ZMpzVZCFK1ZQGzwrMH67kEvu+5xKMx9Qxn0rVlgbPCsxvtoOVom5wMsFole979o/PVP0cSqn8NHhWIOB14/Nc+iO8OM+9+p06mixEqdrR4Fmh+bXPVdEAQa97SZrVpwcmSWuWeaVqQoNnhbIThIB93zNW/fGeAPHZNOdHpqt+HqXUQho8KxRtyHHfMxZiaDLByFT1n3z5Qu+4pqpTqgY0eFZo/nAlWJp57hm9YzM8eWqo6udRSl1Kg2eFcvW4dzTa9z2XIHiCFaSfOjW4JOdSSlk0eFYo5Pfgcckly1wibIqFONU/sWQzgU72T7L3jNZAlVoqyy4xyOWoMehhaPLSMZdb2kIcuTDGf3/gMI1BL80NPlpCXppDPloafPZ7H+GAB5dIniOX5oXeCUSE3RuaHTmeUio/DZ4OaAx6FwTPPRtbCHjdDE4mGJ5MMDSV4ETfBOPxJNndOx6X0NzgoznkpSXkY+vqRq5sj5RdlmM947hdwq51TWUfQym1OA2eDsh139PrdnH9+oU1wNlUmpGpWYanEgxlBdbhyQRnBqY40DXKh9+wFber/Nroke4xXAI7O5vKPoZSqjANng7I1eOej9ftoi3ipy2yMB/nke5R/umpFznVP8GVHeXXPgEOnR/DJcKOtdGKjqOUyk07jBwwP0FIua7siOD3uDjQNerI8Q50jXL0wpgjx1JKXUqDpwMaAx4qaGXP8bpdbF/TyOELo4710v/qxRGO9Yw7ciyl1EUaPB0gIo49MXNnZxPx2TTHHcwWv+/sMCf6NIAq5SQNng7J1WlUji1tYRp8bp7rGnHkeBlPnx7mpGZhUsoxGjwd0hh0pu/N7RJ2rIly9MIYiaSzA+yfPj3EmSWa9aTUSqfB0yFO1TwBdnZGmU0Znu9xtrPHGPjlqUF6RuOOHlepeqTB0yGlDFdazMZYiEjA41ivezZjoHdMg6dSldLg6ZDGoBeHZlniEuHatVFe6B0nPpty5qBZJmeSjh9TqXqjwdMhbpcQ8js352BnZxPJtOFIFcZpTiacD8hK1RsNng6an1W+EuuagzQ1eDngcK87wFRCa55KVUqDp4Oc7DQSEXaubeJE34TjzeypREqffaRUhTR4OsipaZoZOzujpA0c7na+132qCvdSlaonGjwd5GTNE2B1NEAs7K9O0107jZSqiAZPBzk5XAnspntnlNMDk4zFZxffoQQTGjyVqogGTwf5PC6CPmd/pDvXRjHAofPOjvmc0h53pSqiwdNhTjfd2xsDrI4GHB8wr2M9laqMBk+HOR08wap9vjg0xfCkc8+Bn9ThSkpVRIOnw5y+7wlwrf04jYMONt0nZ7TZrlQlNHg6rBo1z5aQj3XNQUd73XWgvFKV0eDpMKfHembs7GyiezRO//iMI8dLpWFaO42UKpsGT4cFvG58Hud/rDvWRhHgwPkRx46p9z2VKp8GzyqoRtM9GvSyMRbiwLlRjHFmauWU3vdUqmzLLniKyHUi8ksROSgi3xeRxlqXqVROJgjJtrMzSv/EDD0O5ePUgfJKlW/ZBU/gK8DdxphrgfuAP61xeUoWbajOfc/ta6K4BMfGfGqnkVLlW47B82rgcfv1vwG/XcOylKUaw5UAwn4PW9rCHOgacaTprjVPpcq3HIPnIeCN9uu3AutqWJayVOOeZ8bOziaGp2bpGp6u+Fg6RVOp8tUkeIrIQyJyKMfX7cC7gTtFZB8QAXJOqxGRO0Rkr4js7e/vX8riLyrk9+BxOfRMjnm2rW7E7RJHxnzqFE2lyledno1FGGNuWWSTWwFE5Crg3+U5xr3AvQB79uxZdpl9G4MehiadzYQEEPS5uaojwsHzo7zh2tW4Knhw0mzKkEimqzK0SqmVbtn91YhIu/3dBfwF8KXalqg81RosD1av+1g8ydnBqYqPpbVPpcqz7IIn8HYReQF4HugG/r7G5SlLNe97bl3ViNftUNNde9yVKsuyC57GmM8aY66yv+42To0IX2LV6nEHK2/oNasaOXh+lFSFzyLSBCFKlWfZBc+VoprNdoDrOqNMJVKc6p+o6Dha81SqPBo8q6Qx4KFKHe4AXNkRwe9xVTxgXqdoKlUeDZ5VIiJEqth097pdbF/TyOELoyRT6bKPowPllSpPweApIteIyGtFJDxv+eurW6yVYW1z0PFnGmXb2dlEfDbNC73lN911iqZS5ck7zlNE3g/cCRwF/k5EPmCMud9e/T+AHy1B+S5ru9Y1sWtdE4lkmrH4LOPxJGPTs4zFZxmbTjIxM0sFlUa2tIVpDHj42Yl+tq6OIGWM+YzPpkmm0njc2ghRqhSFBsn/EbDbGDMhIhuB74jIRmPMZ4Eq3s1beXweF7Gwn1jYf8lyYwwTM0nG7KA6Hk9yemCi6IDqdgmvurqd7z/XzYn+Ca5sj5RVvslEimhQg6dSpSgUPN3GmAkAY8wZEXk1VgDdgAZPR2Tui0YCXtY2BQGrGd09UnzKuZduaObxF/p56EgvV7SFy6p9TiWSVR2XqtRKVKi60SMiuzJv7EB6GxADrq1yuepWZ3NDSdt73C5uvrqdc8PTHOsdL+ucOtZTqdIVCp7vAHqyFxhjksaYdwC/XtVS1bHO5iClVh5fsqGZ5gYvDx3tLStVnU7RVKp0eYOnMabLGNMzf7mINAGvrmKZ6lrA66Y15CtpH7dLuPmaDrpH4hy9MFbyOXWgvFKlyxs8RWSdiHxZRB4Ukf8kIg0i8hngONC+dEWsP6U23cHq2Y+FfTx0tI90ibVPbbYrVbpCzfavAReAzwPbgSeBNcC1xpgPLEHZ6tba5mDJ+2Rqnz1jcQ6dL23WkY71VKp0hYJnizHmHmPMj40xdwEdwB/kasorZ0WDXhqDpada3dkZpT3i5+HnS6t9TiVSpCtMMKJUvVlshlGziLSISAtW51FD1ntVRZmhS6VwifDarR30j8+UlK7OGJie1aa7UqUoFDyjwL6sr0bgWfv13uoXrb6Vc98TYPuaRlY1Bnj4aF9J6eq0x12p0hTqbd9ojNlsjNmU42vzUhayHsXCPgLe0mf9uES4ZWsHg5MJ9p8bLnq/SX0YnFIlKdTbvkFEolnvXyMinxWRu0SktLE0qmQiUlbTHWDr6ghrm4I88nwfyXRxcz215qlUaQpVbb4FhADsmUbfBl4EdgF/W+2CKehsKa/pLiLcsrWd4alZnj07UtQ+GjyVKk2h4Bk0xnTbr/8D8FVjzGeAdwE3VL1kilWNgbIfYXxVR4R1zUEePdZXVL5PfYa7UqUpFDyz/2pvBh4GMMZUkERNlcLtElZFA2XtKyK8btsqRqdneebM0KLb6ywjpUpTKHg+IiLfEpHPAs3AIwAishpILEXhlDXXvVxb2kJsbA3x2Av9zC5S+9THcShVmkLB84PAvwJngFcaY2bt5auAj1S3WCpjTVPpiUIyRIRbtrUzHk/y1OnCtc9k2hDXsZ5KFa1Q8LzaGPMNY8xfAwOZhcaYXwGVPXVMFS3gddM2L4lyKTbHwmxpC/HTF/pJJAvXPrXTSKniFQqeX896/ct567S3fQl1tpTfdAd43dYOJmeS/PLUYMHtNEGIUsUrtsNofsNRM8kvoXLHe2asbw1xVUeYx1/oL9g0104jpYpXKHiaPK9zvVdVFAl4aWqo7DEZt2ztYHo2xS9O5q99anYlpYpXKHVPp4h8DquWmXmN/X5t1UumLtHZHGRkanbxDfPu38DWVRGeONHPjZtbCfrcC7aZ0Ga7UkUrVPP8Uy4mAcm8zrz/s+oXTWWrtOkOcMu2DuKzaZ44MZBz/ZR2GClVtLw1T2PMPy5lQVRhrWE/DT53RTOBVkeD7FjTyC9ODnDTlTEC3ktrnxMaPJUqmj6s+zJSTob5+V66sYWZZJrzI9ML1s2mzKLDmZRSFg2el5FKZhtltDda0z37x2dyrtdOI6WKo8HzMtIRCeB1VzZKrDHgwed2MTCRO3hqXk+lilNW8BSRjzpdELU4l0tYU2HHkYgQC/vy1jx1lpFSxSm35vmfHC2FKpoTve6xiD9/zVODp1JFydvbLiJj+VYBlf8Fq7KsaQriEqjkYZdtYT8Hu0aZTaXxui/9/6lTNJUqTqGa5whwpTGmcd5XBOt57qoGfB4X7Y3lJwoBaIv4MZCz9qlTNJUqTqHg+TVgQ551X8+zXC2Bcp+smRGzszTluu+pve1KFafQ0zP/whjzdJ51/7V6RVKLqfS+ZyZ45qp5TifSJT2yWKl6VVKHkYjc48RJReStInJYRNIismfeug+LyAkROSYiv+HE+VaakN9DS6j8RCE+j4umoDd/j7vWPpVaVKm97W906LyHgLcAj2cvFJFtwNuA7cDrgb8VkYUZLFTFTfe2iJ+BidxPU9FHcii1uFKDpyN5PI0xR40xx3Ksuh34hjFmxhhzGjiBPqkzJyea7v0TMxizsImuc9yVWlypwfMlVSnFRWuBc1nvu9D0dzk1h3yE/OVXytsifhLJNGPxhYFSO42UWtyiwVNENovI90VkAOgVkftFZHMR+z0kIodyfN1eaLccy3L2XojIHSKyV0T29vf3L1acFamSue6FOo10rKdSiyum5vl14FtYT81cA3wb+JfFdjLG3GKM2ZHj6/4Cu3UB67LedwLdeY5/rzFmjzFmT1tbWxGXsfJUct+zLZJ/uJLOMlJqccUETzHG/F9jTNL++ieq9xiOB4C3iYhfRDYBVwI5h0spa6aQz1PeDNtMgpB+HSivVFmK+ct7VETuFpGNIrJBRP4M+IGItIhISzknFZE3i0gXcKN9rB8DGGMOY9VyjwA/Au40xmgbMg8rUUigrH1FhFjEx0COmud0IpWzI0kpdVGhZxhl/K79/Y/nLX83Vg100fuf8xlj7gPuy7PuE8AnSj1mvVrX3MCZgamy9m0L+zk7tHDftIGpRIqQv5hfD6Xq06J/HcaYTUtREFWe1dEAHreQTJVeU4xF/DzXNUoimV7Q/J9MJDV4KlVAMb3tXhF5v4h8x/76ExGp7Dm4yjEet4vOMsd8ttk97oOTOea4a4+7UgUVc8/zi8Bu4G/tr932MrVMbIiFytqvUI+7DpRXqrBC+Tw9xpgk8FJjzHVZqx4RkeeqXzRVrNWNAXweV8kPb2sN+RHI2eNeyVM6laoHhWqemSFCKRHZklloD5DXv6xlxOUS1pUxYN7ncRFt8ObscdexnkoVVqhHIDPb50NYw5VO2e83Au+qZqFU6Ta0hjjZP1nyfm32HPf5dKynUoUVCp5tIvJf7NdfBtzAJBAArgcerXLZVAk6Gv0EfS6mE6U13WMRP2fPTGGMQeTi7FjtMFKqsELNdjcQBiJYQVbs9x57mVpGRIT1LaVP12wL+0mkFiYISaYN8VkNoErlU6jmecEY8/ElK4mq2PqWEMd6JkraJ7vHPRq8dATa5EySgFfTqSqVS6GapyO5O9XSaYv4S05TN/c8I+1xV6okhYLna5esFMoxG1pLG/PZGPDg87hy9rjrWE+l8iv0ALihpSyIcsaGEu97ikjeHndNiqxUfuXlM1PLVnPIR2OwtDnpbRF/nrGe2mxXKh8NnivQxhKb7rGwj5Hp2QUzlHSgvFL5afBcgda3ltZ0b4tYOUHnP5JjUjuMlMpLg+cK1BjwlvRc91jYByzscU8k08ymSht0r1S90OC5QpXS6x4LWwlCdI67UsXT4LlClTLbyOt20dTgzTPHXZvuSuWiwXOFCvk9c7OHihEL5+5xn9Kap1I5afBcwTaW0HHUFrHGeqbnPfhNB8orlZsGzxVsXUsDUuQk21jYz2zKMDY9e8lynaKpVG4aPFewgNfNqsbiHk2caeIPTCQuWa41T6Vy0+C5wm0osumeeRhc/3j8kuU6RVOp3DR4rnCdzQ24i/iUIwEPfo+L/nk1z+lEmlS69McaK7XSafBc4XweF6ujiz/fSETy97hr7VOpBTR41oGim+6RPM8z0gQhSi2gwbMOrG0K4nEt3u0eC/sZzZUgRGueSi2gwbMOeNwuOot4NPHFHvd5CUK0x12pBTR41oliMi1d7HGfHzy12a7UfBo868SaaBCfp/DH3Rr2ISzMrqQdRkotpMGzTrhcwrpFmu6ZBCHzm+06UF6phTR41pFi0tS1RfwLmu3TiRTG6FhPpbJp8KwjHY1+gr7CH3lb2M/AvAQhaQMjU7MF9lKq/mjwrCMismiez1gkd4KQIxfGqlk0pS47GjzrzPqWwk33uR73efc9XxyaYlRrn0rN0eBZZ9oifkJ+d971sUju4UrGwMHzo1Utm1KXEw2edaizOX/TPeK3EoTM73EHq/Y5MpXIsZdS9UeDZx3KPC0zFxHJ2eOeobVPpSw1CZ4i8lYROSwiaRHZk7W8VUQeFZEJEfmbWpStHrSGCz/byOpxz13DPDc0zfCk1j6VqlXN8xDwFuDxecvjwH8DPrTkJaojYbtpnk8sYiUImUnmnpaptU+lahQ8jTFHjTHHciyfNMY8gRVEVRW1Fmi6x8K5H8mR0TWstU+l9J5nnYoVaLq35elxz6a1T1XvPNU6sIg8BKzKseojxpj7HTj+HcAdAOvXr6/0cHWnJZS/5tkashKE5Opxz+ganmZoMlHwOEqtZFULnsaYW6p1bPv49wL3AuzZs0cnXpeoULPd63bRHPIVrHmCVft81VVtThdNqcuCNtvrlN/jJhzI/78zFvYVrHkCnB+eZnCRbZRaqWo1VOnNItIF3Aj8QER+nLXuDPC/gD8QkS4R2VaLMtaDWIEmd64EIbnovU9Vr6rWbC/EGHMfcF+edRuXtjT1qzXs58zgVM51mQQho9OzNDfkD7LdI3EGJmYKdkAptRJps72OFbrvOfc8o0Xue4LWPlV90uBZx5obfOR7qGa+7Eq5XLBrn0rVEw2edcztEpoavDnXhf0eAl7Xoj3uGQe7tPap6osGzzqXb567iBAL+4uqeQJcGI0XHWiVWgk0eNa51sV63EsIiIf03qeqIxo861yhDEttET9j8SQzs8U9t/3CaJy+cU1LoOqDBs86Fw168bpz9xotliAkF619qnqhwVPlHbI0lyBkovjaZM/ojNY+VV3Q4KloCeVuumcShPSPl5Z+TnveVT3Q4Knydhp57AQhpY7h7B2boW9Ma59qZdPgqQrn9gznf55RIb86N0K8yI4mpS5HGjwVQZ+bBl/uxxG3RYpLEDLf4ESCHxy4wMn+CSeKqNSyo8FTAfk7jWJhP8m0YXRqtuRjziTTPHVqiIeO9DI6Xfr+Si1nGjwVAK15Oo1iESuoFjvTKJe+8Rl+ePACB7pGSKU1b7VaGTR4KqDAcKXw4s8zKkbawKHzY/zg4AV6RrUzSV3+NHgqwHqmkeQYK59JEOJU1qSJeJJHnu/jFycGtENJXdY0eCrAem5RNLgww5KI0Bb20zMWx5TYaVTImcEpHjxwgRN9444dU6mlpMFTzcn3JMxNsTBnB6f4xjPnHK0tJpJpnj49zL8d6WVkSp8Dry4vGjzVnFie+563bu/g1m0dHO4e5fOPHOfFodyP7ihX//gMPzrUwwu9WgtVlw8NnmpOvh53lwivvrqdO27ajAHuffwkjx3rK3nsZyFpA8+eHdYaqLpsaPBUc6JBL558z+UA1reGeN9rrmT7mig/OdLL3//8NGMOjt9MG3jy1JCj91aVqhYNnmqOyyU0F0iODNZspLe9dB1vuX4tLw5N8blHjvN8z5hjZRiaTHD0gjbf1fKnwVNdotATNTNEhD0bW7jz1VcQDXr52i/P8uCBbpKptCNlOHR+lLG4zkhSy5sGT3WJQo/lmK+9McB7XrWFG7e08ouTg3zxpycdeY5RMm146tRQxcdRqpo0eKpLFHosRy5et4vf2rmG//hrGxidnuVvHj3OvrOV37fsH5/R3ne1rGnwVJcI+z34PaX/Wmxd3cj7br6Sdc0NfPfZ83xz7znGK2x67z83wuRMsqJjKFUtGjzVAsXc98wlGvTy7ldu4tZtHRw6P8pf/fB5/u6JUzx1epCJMoJgMmV4+rQ239Xy5Kl1AdTyEwv76R4pL3lHZkzotjWNPHdulIPnR7h/fzfff66bzbEw166Nsm1NIyF/cb96F0bjnOyfYEtbuKzyKFUtGjzVAvmmaZaiPRLgddsC3LK1nZ6xOAfPj3Kwa5T79p/n/ufOs6XNDqSrG2lYJJA+e3aYNdEgwTwJm5WqBVkJA5L37Nlj9u7dW+tirBgzyRTf3Xfe8eMaY7gwagfS86MMTSZwCVzRHmbHGqtG2uDLHUjXNgd51VVtjpdJqUJEZJ8xZk+udVrzVAv4PW7CAQ8TcWc7a0SENU1B1jQFuXVbB92jcQ7ZgfRff3We+5/r5sbNrbzm6vYFtczzw9OcGZhkYyzkaJmUKpcGT5VTLORzPHhmExHWNgVZmwmkI3GePDXIz08MsO/sMK/d2s7LNrXizpouuu/sMKuiAQJebb6r2tPedpVTqeM9KyEirG0O8tu7O7nzNVewpinAgwcu8L8feoEj3WNzY0Znkmn2nR1esnIpVYgGT5VTucOVKrWmKci7X7GJd9y4AZcI//TUWb7yxGnOD08DcHZwinMOp8RbzGwqTSKZJq3PX1JZtNmucmpu8OESK9PRUhMRrlnVyJXtEZ45M8RDR3v5wmMnuH5dE6/b1sHes0N0NAbwlTGYv1ij07N0DU/RNTzN4MTFNHkusRKoeFyC2/6yXrtwu8DtcuFxCQGvi+YGH60hP41BD5LrGSfqsqbBU+XkdglNDT6GJmuXX9PtEn5tcyu71jXx2LF+fnFygIPnR7npyhhNQR+vuabdsXMZY+ifmKFreJrzw9OM57nfmzaQThmSqeL/q3jsbFUtWV+5HnmiLi8aPFVereHaBs+MgNfN63es4mWbWvjxkR4ePdbPM2eG+ZObt/BHN225pFOpFMlUmgujcc6PWAFzJulMVqgF50kb+sdnLkma4nELLQ0+WsK+ue8Rv9ZQLyc6zlPldap/gieXYXajc0NT/ODgBV4cmiLs9+B1lxZw2iMB1rc20Bb2s7Y5SFPQuyyCltsFYb+XSMBDY9D6Hgl4aAx4dYRBjeg4T1WWpexxL8XVqyK8YccqTg1M8OyLIyXtmzaGQ+fHeOxYH7N20zsS8LC+pWHua01TEK976ftSU2nrXuvo9CzYHWQZPo/rkmBqvfYS9Lrxe1y4yqx9q/LVJHiKyFuBe4CtwA3GmL328tcBfwX4gATwp8aYR2pRRmUl+vC6ZS7I1NrqaIAr2sOsbQricgk71zXxpus7yzrW0OQM39rbxeHuMc4NTXF2cJLD3VZGfLdLWBMNWMG0NcS65iDRGtdOE8k0gxOJSzqvsvk8LgJeF36Pm4DXRcDrJmC/zizz24G2XrlEHO1krFXN8xDwFuDL85YPAL9ljOkWkR3Aj4G1S104dVFr2EfPaOUJjsvl97jY1BbiyvYwkYBznSwtIT9/dNNm9p4Z4mT/JADj8VnODU3x4tAUZ4emeOr0ED8/OQhYwSkW9hEL+7O+rPfLoUmdSFrDqUBT+OWzsbWBl18Rc+x4NQmexpijwIL/5MaYX2W9PQwERMRvjKndX2+dawn5axI8Y2EfV3ZEWN/SUHaH0GLcLuFlm1tpbwzwzOkhIgEv29ZE2bYmCkAynaZnNM654WkGxmcYmJjh3NAUB7tGya6LR/weWu1g2haxAuuqxsCiz4NSl7flfM/zt4FfaeCsrVIey5HhdlnJPsJ+L7OpNMm0sb6nrO+pzPus5cl0GhFhU8yqZTY1LF3g2RQL0dLg44kTA9b9RpvH5aKzuYHO5oZLtp9NpRmaTDAwMcPARGIusB69MMbes6m57doifrauinD1qsaq/hNQtVG14CkiDwGrcqz6iDHm/kX23Q58Eri1wDZ3AHcArF+/voKSqkJiJXQaicDmWIhrO6N5syMtV9EGL7+xvYOnzwxxZqDwDCav20VHY4COxsCCddOJFAMTM7w4NMWxnnF+fmKQx48PEPS6uaojzDWrG7mqPaLp9VaAqv2GG2NuKWc/EekE7gPeYYw5WeD49wL3gjVUqaxCqkUFfW4afG6mEqmC261rCbKzs+myHvztcbt4+ZYY7ZEJ9p0dopyHgQZ9bta1NLCupYFXXBEjPpvieN8Ex3rGeL5nnOe6RnEJbGgNcc2qCNesaiQW9i2LoVKqNMuqeiAiTcAPgA8bY35e4+IoW2vYx9TQdM51q6J+rutsWrbDmspxRXuYWNjHz44P5J1pVKyA1821a6NcuzZK2hi6hqZ4vmec53vG+eGhHn54qIfWkI9rVkVY3xqa64SqxVApVZqaDJIXkTcDnwfagBFgvzHmN0TkL4APA8ezNr/VGNNX6Hg6SL66jnSPsf/cyCXLWkI+dq1rYlV0YdN1pZhNpXn69BBnB6uTiGR4KsGxnnGe7xnjZP8kqaxEAk1Br9WjH7m0h7+pwYtLa6llKae3vdAgeZ1hpBbVOxbn4aPW/6/GoIfrOptY19KwyF4rx5mBSV4cmqJ3LF61Ma+JZNrugJq52BFlv47PXrx/4HYJrSEroLaGfYT9Hhp8Hhrs2yuZ10GfW4PsPE4Hz2XVbFfLU0vIR8jvZsfaKJtjobq7P7cxFmJjLIQxhqHJBD1jcXrH4gyMJ0g6lHbK53HNZdnPZoxhMpGa69HPDqrHescvqa1mE6xbBvODqt/rpr4+vYsaAx78Xhe7N7Q4cjwNnmpRXreL39q5pu6nAIoIrWE/rWE/29dESaUNAxMz9IzG6RmLMzSZwOmGnIgQ9nsI+z0LHkFijGEmmWYqkWIqkbS/Z7++uGx8Zpbe8Tgzs9VJfnI5cLng1u2rNHiqpVXvgTMXt0vmhixdh9X07hu3aqVdw9NMzhQeoVApEbGmYXrdjjzxdKVbETOMlFqJfJ6Lg+p3b4Ce0Tgn+iboGp6qSVJpVV0aPJWqklXRAKuiAeKzKU4PTHKyf4KxaZ17vlJo8FSqygJeN1tXN7J1dSN943FO9k1ybmjKsc4mVRsaPJVaQu2RAO2RALs3NHNmcJKTfRMMT80uvqNadjR4KlUDPo+LqzoiXNURYXBihpP9k/SNx5mIJ/X+6GVCg6dSNZYZ/gTW8KOJmSRj8STj8VnG40nGpq3vi+UXUEtLg6dSy4iIEAl47cTPlw6YT6bSjMeTVkC1A+tMMsVsypBIpueeL6/3UpeGBk+lLhMet4vmkG/RJMvptCGRSpNIpZlNZr4bEqkUybRxfCD/5cLpjF8aPJVaYVwuIeByL4vHg6xkmvdKKaXKoMFTKaXKoMFTKaXKoMFTKaXKoMFTKaXKoMFTKaXKoMFTKaXKoMFTKaXKoMFTKaXKoMFTKaXKoMFTKaXKsCKe2y4i/cDZEneLAQNVKM7lcP56vvZ6P389X3s5599gjGnLtWJFBM9yiMjefA+zX+nnr+drr/fz1/O1O31+bbYrpVQZNHgqpVQZ6jl43lvH56/na6/389fztTt6/rq956mUUpWo55qnUkqVbcUHTxF5vYgcE5ETInJ3jvUiIp+z1x8QkZc4dN51IvKoiBwVkcMi8oEc27xaREZFZL/99VEnzp11/DMictA+9t4c66ty7faxr866rv0iMiYiH5y3jaPXLyJfFZE+ETmUtaxFRP5NRI7b35vz7Fvw96TMc39aRJ63f7b3iUhTnn0Lfk4VnP8eETmf9fP9zTz7VnTtBc7/zaxznxGR/Xn2rej68/2tVf2zN8as2C/ADZwENgM+4Dlg27xtfhP4ISDArwFPOXTu1cBL7NcR4IUc53418GAVr/8MECuwvirXnudz6MEaM1e16wd+HXgJcChr2aeAu+3XdwOfLOf3pMxz3wp47NefzHXuYj6nCs5/D/ChIj6biq493/nnrf8M8NFqXH++v7Vqf/YrveZ5A3DCGHPKGJMAvgHcPm+b24GvGcuTQJOIrK70xMaYC8aYZ+3X48BRYG2lx3VYVa49h9cCJ40xpU5kKIkx5nFgaN7i24F/tF//I/CmHLsW83tS8rmNMT8xxiTtt08CnaUcs9LzF6nia1/s/CIiwL8H/qWM8hVz7nx/a1X97Fd68FwLnMt638XCAFbMNhURkY3A9cBTOVbfKCLPicgPRWS7k+cFDPATEdknInfkWF/1a7e9jfx/ONW8foAOY8wFsP7IgPYc2yzFz+HdWLX8XBb7nCrxJ/Ztg6/mabYuxbXfBPQaY47nWe/Y9c/7W6vqZ7/Sg6fkWDZ/eEEx25RfAJEw8F3gg8aYsXmrn8Vqyl4HfB74nlPntb3CGPMS4A3AnSLy6/OLl2MfR4dfiIgPeCPw7Ryrq339xar278BHgCTwz3k2WexzKtcXgS3ALuACVtN5QfFyLHN6CM7bKVzrdOT6F/lby7tbjmVFXf9KD55dwLqs951AdxnblEVEvFgf5j8bY/51/npjzJgxZsJ+/f8Ar4jEnDi3fcxu+3sfcB9WEyVb1a49yxuAZ40xvTnKV9Xrt/VmbkXY3/tybFPN34F3ArcBv2/sm2zzFfE5lcUY02uMSRlj0sD/yXPcqv4OiIgHeAvwzQLlrPj68/ytVfWzX+nB8xngShHZZNeA3gY8MG+bB4B32D3PvwaMZqr6lbDv8/wdcNQY87/ybLPK3g4RuQHr8xis9Nz28UIiEsm8xuq8ODRvs6pc+zx5ax3VvP4sDwDvtF+/E7g/xzbF/J6UTEReD/xX4I3GmKk82xTzOZV7/uz712/Oc9yqXHuWW4DnjTFdecpY8fUX+Fur7mdfbg/X5fKF1aP8AlaP2kfsZe8B3mO/FuAL9vqDwB6HzvtKrOr/AWC//fWb8879J8BhrB6+J4GXO3jdm+3jPmefY8muPasMDVjBMJq1rGrXjxWkLwCzWDWKPwRagYeB4/b3FnvbNcD/K/R74sC5T2DdT8t8/l+af+58n5ND5/+/9ud6ACsgrK7Gtec7v738HzKfd9a2jl5/gb+1qn72OsNIKaXKsNKb7UopVRUaPJVSqgwaPJVSqgwaPJVSqgwaPJVSqgwaPFcYETEi8pms9x8SkXscOvY/iMjvOHGsRc7zVjtDzqMOH/ceEfmQw8dckp9JuURkj4h8rsR9HhORmj1n6HKhwXPlmQHeUoWZOhUREXcJm/8h8J+NMa+pVnnqgYh4jDF7jTHvr3VZViINnitPEutRA3fNXzG/liQiE/b3V4vIT0XkWyLygoj8lYj8vog8LVaexS1Zh7lFRH5mb3ebvb9brNyVz9hJKP4467iPisjXsQZrzy/P2+3jHxKRT9rLPoo16PlLIvLpedsXVU4R2SAiD9tleVhE1uc49xYR+ZFYySh+JiLX2Ms7xMq9+Zz99XIR2SiX5qnMWZsXkd12+faJyI/l4tTA94vIEbs838ixX1BEvmGv/6aIPJWp+WU+I/v174jIP9iv20Tku/bP/BkReYW9/B4RuVdEfgJ8zf6ZPWivC4mVIOQZEfmViNye6/xAcH4Z1UKeWhdAVcUXgAMi8qkS9rkO2IqVVuwU8BVjzA1iJZZ9H/BBe7uNwKuwEk48KiJXAO/Amtr5UhHxAz+3/3jBmqe8wxhzOvtkIrIGK8flbmAYK6vOm4wxHxeRm7HyUOZKjFtMOf8GK9XeP4rIu4HPsTAd2b1YM1+Oi8jLgL8Fbra3/akx5s12bTkM5EyiO+96vFjJTW43xvSLyO8Cn8DKpnQ3sMkYMyO5EyK/F5gyxuwUkZ1YCVMW81ngr40xT9j/HH5s/1zA+pm+0hgzLSKvztrnI8Ajxph32+V4WkQeAv64jPPXPQ2eK5AxZkxEvga8H5gucrdnjD2vXUROApngdxDIbj5/y1iJJo6LyCngGqz5yDuzarVR4EogATw9P3DaXgo8Zozpt8/5z1gJdb/nQDlvxEpGAdYUxUv+iYiVfeflwLdF5pLq+O3vN2P9M8AYkwJGJU8G8nmuBnYA/2Yf0401XRGsaYP/LCLfy3N9v44VtDHGHBCRA0Wc7xZgW1b5G8WeIw48YIzJ9bnfCrxRLt73DQDryzx/3dPguXL9b6waxN9nLUti36oR66/Ol7VuJut1Out9mkt/T+bP5zVYc+TfZ4z5cfYKu9Yzmad8uVKBFaPYcs4vYzYXMGKM2VXkOed+brZAjm0EOGyMuTHHun+HFaDeCPw3EdluLiZJzlfGXMuzz+sCbpwfJO1gWuhn/tvGmGM59tF52iXSe54rlDFmCPgWVudLxhmsJh1Y2bK9ZRz6rSLisu8vbgaOYTUZ32s3XRGRq8TKkFPIU8CrRCRmN4/fDvy0jPLk8gus7DgAvw88kb3SWLkeT4vIW+3yiohcZ69+GKsZnbmX2wj0Au0i0mrflrgtxzmPAW0icqO9r1dEtouIC1hnjHkU+DOgCetWQLbH7XIiIjuAnVnrekVkq32cN2ct/wlWYhXs/XYV/pEA1uf0PvsfJyJyfRHnV3lo8FzZPgNk97r/H6yA9TTwMvLXUAo5hhXkfoh1zzAOfAU4Ajxrd6x8mUVaNXbT+8PAo1gZdZ41xuRKGVaO9wPvspuf/xFY8PA9rGDxhyKSyeaTefTCB4DXiMhBYB+w3RgzC3wcK+A/CDyf43oSwO8An7SPuR/r1oAb+Cf7eL/Cuk85Mm/3LwJhu7x/Bjydte5u+5yPcPE2QOYa99idPEewslUt5i+x/mEesD+nvyzi/CoPzaqk1DIjIo+Rv8NMLRNa81RKqTJozVMppcqgNU+llCqDBk+llCqDBk+llCqDBk+llCqDBk+llCqDBk+llCrD/wd+EcxCbw6+iAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_axis = np.arange(query_batch_size*num_bo_iters+1)\n",
    "\n",
    "bo_records = np.array([[y_all[i].item() for i in bo_record] for bo_record in bo_records])\n",
    "bo_records_mean = bo_records.mean(axis=0)\n",
    "bo_records_std = bo_records.std(axis=0)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "plt.plot(x_axis, bo_records_mean, label=\"GP-ST\")\n",
    "plt.fill_between(x_axis, bo_records_mean-bo_records_std, bo_records_mean+bo_records_std, alpha=0.4)\n",
    "\n",
    "plt.xlabel(\"Number of molecules queried\")\n",
    "plt.ylabel(\"Top-1 ESR2\")\n",
    "#plt.ylim(3.5, 9.0)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac81272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"outputs/dkt_bo_records.pkl\", \"wb\") as output_file:\n",
    "    pickle.dump(bo_records, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6b7680",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
