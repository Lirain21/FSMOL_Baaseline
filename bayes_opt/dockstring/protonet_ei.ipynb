{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c583b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pyprojroot import here as project_root\n",
    "\n",
    "sys.path.insert(0, str(project_root()))\n",
    "\n",
    "from fs_mol.data.dkt import get_dkt_batcher\n",
    "from fs_mol.utils.torch_utils import torchify\n",
    "\n",
    "from bayes_opt.bo_utils import load_dockstring_dataset, run_gp_ei_bo, min_so_far, task_to_batches, PrototypicalNetworkFeatureExtractor\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b7123ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = load_dockstring_dataset(\"dockstring-dataset-subsampled.csv\", \"../../fs_mol/preprocessing/utils/helper_files/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eec150c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batcher = get_dkt_batcher(max_num_graphs=100)\n",
    "dkt_batches = torchify(\n",
    "    task_to_batches(task, batcher), \n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "532dfce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PrototypicalNetworkFeatureExtractor(\n",
       "  (graph_feature_extractor): GraphFeatureExtractor(\n",
       "    (init_node_proj): Linear(in_features=32, out_features=128, bias=False)\n",
       "    (gnn): GNN(\n",
       "      (gnn_blocks): ModuleList(\n",
       "        (0): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (6): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (7): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (8): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (9): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (readout): CombinedGraphReadout(\n",
       "      (_weighted_mean_pooler): MultiHeadWeightedGraphReadout(\n",
       "        (_scoring_module): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=12, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_transformation_mlp): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_combination_layer): Linear(in_features=768, out_features=512, bias=False)\n",
       "      )\n",
       "      (_weighted_sum_pooler): MultiHeadWeightedGraphReadout(\n",
       "        (_scoring_module): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=12, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_transformation_mlp): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_combination_layer): Linear(in_features=768, out_features=512, bias=False)\n",
       "      )\n",
       "      (_max_pooler): UnweightedGraphReadout(\n",
       "        (_combination_layer): Linear(in_features=1408, out_features=512, bias=False)\n",
       "      )\n",
       "      (_combination_layer): Linear(in_features=1536, out_features=512, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2560, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_weights_file = \"../../../fs-mol-checkpoints/PNSupport64_best_validation.pt\"\n",
    "\n",
    "protonet_model = PrototypicalNetworkFeatureExtractor.build_from_model_file(\n",
    "    model_weights_file,\n",
    "    device=device\n",
    ").to(device)\n",
    "\n",
    "protonet_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8645752d",
   "metadata": {},
   "outputs": [],
   "source": [
    "representations = []\n",
    "\n",
    "for features in dkt_batches:\n",
    "    representation = protonet_model.get_representation(features)\n",
    "    representations.append(representation)\n",
    "    \n",
    "del protonet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90211d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = task.samples\n",
    "\n",
    "x_all = torch.cat(representations, dim=0)\n",
    "y_all = torch.FloatTensor([float(x.numeric_label) for x in dataset]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7406af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_init_points = 16\n",
    "query_batch_size = 1\n",
    "num_bo_iters = 20\n",
    "kernel_type = \"matern\"\n",
    "init_from = 1600\n",
    "noise_init = 0.01\n",
    "noise_prior = True\n",
    "\n",
    "num_repeats = 20\n",
    "\n",
    "bo_records = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fc4efa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 20/20 [26:13<00:00, 78.68s/it]\n"
     ]
    }
   ],
   "source": [
    "for repeat in tqdm(range(num_repeats)):\n",
    "    bo_record = run_gp_ei_bo(dataset, x_all, y_all, num_init_points, query_batch_size, num_bo_iters, kernel_type, device, init_from, noise_init, noise_prior)\n",
    "    bo_records.append(min_so_far(bo_record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4752fcaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f7f3c3f13d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_axis = np.arange(query_batch_size*num_bo_iters+1)\n",
    "\n",
    "bo_records = np.array([[y_all[i].item() for i in bo_record] for bo_record in bo_records])\n",
    "bo_records_mean = bo_records.mean(axis=0)\n",
    "bo_records_std = bo_records.std(axis=0)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "plt.plot(x_axis, bo_records_mean, label=\"GP-ST\")\n",
    "plt.fill_between(x_axis, bo_records_mean-bo_records_std, bo_records_mean+bo_records_std, alpha=0.4)\n",
    "\n",
    "plt.xlabel(\"Number of molecules queried\")\n",
    "plt.ylabel(\"Top-1 ESR2\")\n",
    "#plt.ylim(3.5, 9.0)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac81272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"outputs/protonet_bo_records.pkl\", \"wb\") as output_file:\n",
    "    pickle.dump(bo_records, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6b7680",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
