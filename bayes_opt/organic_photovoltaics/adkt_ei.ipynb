{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c583b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pyprojroot import here as project_root\n",
    "\n",
    "sys.path.insert(0, str(project_root()))\n",
    "\n",
    "from fs_mol.data.dkt import get_dkt_batcher\n",
    "from fs_mol.utils.torch_utils import torchify\n",
    "\n",
    "from bayes_opt.bo_utils import load_cep_dataset, run_gp_ei_bo, min_so_far, task_to_batches, ADKTModelFeatureExtractor\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b7123ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = load_cep_dataset(\"cep-dataset-subsampled.csv\", \"../../fs_mol/preprocessing/utils/helper_files/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ac1070b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batcher = get_dkt_batcher(max_num_graphs=100)\n",
    "dkt_batches = torchify(\n",
    "    task_to_batches(task, batcher), \n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a342b4f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ADKTModelFeatureExtractor(\n",
       "  (graph_feature_extractor): GraphFeatureExtractor(\n",
       "    (init_node_proj): Linear(in_features=32, out_features=128, bias=False)\n",
       "    (gnn): GNN(\n",
       "      (gnn_blocks): ModuleList(\n",
       "        (0): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (6): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (7): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (8): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (9): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (readout): CombinedGraphReadout(\n",
       "      (_weighted_mean_pooler): MultiHeadWeightedGraphReadout(\n",
       "        (_scoring_module): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=12, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_transformation_mlp): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_combination_layer): Linear(in_features=768, out_features=512, bias=False)\n",
       "      )\n",
       "      (_weighted_sum_pooler): MultiHeadWeightedGraphReadout(\n",
       "        (_scoring_module): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=12, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_transformation_mlp): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_combination_layer): Linear(in_features=768, out_features=512, bias=False)\n",
       "      )\n",
       "      (_max_pooler): UnweightedGraphReadout(\n",
       "        (_combination_layer): Linear(in_features=1408, out_features=512, bias=False)\n",
       "      )\n",
       "      (_combination_layer): Linear(in_features=1536, out_features=512, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2560, out_features=2048, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "  )\n",
       "  (gp_likelihood): GaussianLikelihood(\n",
       "    (noise_covar): HomoskedasticNoise(\n",
       "      (noise_prior): LogNormalPrior()\n",
       "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "    )\n",
       "  )\n",
       "  (gp_model): ExactGPLayer(\n",
       "    (likelihood): GaussianLikelihood(\n",
       "      (noise_covar): HomoskedasticNoise(\n",
       "        (noise_prior): LogNormalPrior()\n",
       "        (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "      )\n",
       "    )\n",
       "    (mean_module): ZeroMean()\n",
       "    (covar_module): ScaleKernel(\n",
       "      (base_kernel): MaternKernel(\n",
       "        (raw_lengthscale_constraint): Positive()\n",
       "      )\n",
       "      (raw_outputscale_constraint): Positive()\n",
       "    )\n",
       "  )\n",
       "  (mll): ExactMarginalLogLikelihood(\n",
       "    (likelihood): GaussianLikelihood(\n",
       "      (noise_covar): HomoskedasticNoise(\n",
       "        (noise_prior): LogNormalPrior()\n",
       "        (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "      )\n",
       "    )\n",
       "    (model): ExactGPLayer(\n",
       "      (likelihood): GaussianLikelihood(\n",
       "        (noise_covar): HomoskedasticNoise(\n",
       "          (noise_prior): LogNormalPrior()\n",
       "          (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "        )\n",
       "      )\n",
       "      (mean_module): ZeroMean()\n",
       "      (covar_module): ScaleKernel(\n",
       "        (base_kernel): MaternKernel(\n",
       "          (raw_lengthscale_constraint): Positive()\n",
       "        )\n",
       "        (raw_outputscale_constraint): Positive()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model_weights_file = \"../../outputs/FSMol_ADKTModel_gnn+ecfp+fc_2022-03-22_15-28-36/best_validation.pt\" #512\n",
    "model_weights_file = \"../../outputs/FSMol_ADKTModel_gnn+ecfp+fc_2022-04-07_12-53-41/best_validation.pt\" #2048\n",
    "\n",
    "adkt_model = ADKTModelFeatureExtractor.build_from_model_file(\n",
    "    model_weights_file,\n",
    "    device=device\n",
    ").to(device)\n",
    "\n",
    "adkt_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5206bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "representations = []\n",
    "\n",
    "for features in dkt_batches:\n",
    "    representation = adkt_model.get_representation(features)\n",
    "    representations.append(representation)\n",
    "    \n",
    "del adkt_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34d6a02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = task.samples\n",
    "\n",
    "x_all = torch.cat(representations, dim=0)\n",
    "y_all = torch.FloatTensor([float(x.numeric_label) for x in dataset]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7406af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_init_points = 16\n",
    "query_batch_size = 1\n",
    "num_bo_iters = 40\n",
    "kernel_type = \"matern\"\n",
    "init_from = 1200\n",
    "noise_init = 0.01\n",
    "noise_prior = True\n",
    "\n",
    "num_repeats = 20\n",
    "\n",
    "bo_records = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fc4efa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 20/20 [46:59<00:00, 140.97s/it]\n"
     ]
    }
   ],
   "source": [
    "for repeat in tqdm(range(num_repeats)):\n",
    "    bo_record = run_gp_ei_bo(dataset, x_all, y_all, num_init_points, query_batch_size, num_bo_iters, kernel_type, device, init_from, noise_init, noise_prior)\n",
    "    bo_records.append(min_so_far(bo_record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4752fcaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 12.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_axis = np.arange(query_batch_size*num_bo_iters+1)\n",
    "\n",
    "bo_records = np.array([[float(-1.0 * y_all[i].item()) for i in bo_record] for bo_record in bo_records])\n",
    "bo_records_mean = bo_records.mean(axis=0)\n",
    "bo_records_std = bo_records.std(axis=0)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "plt.plot(x_axis, bo_records_mean)\n",
    "plt.fill_between(x_axis, bo_records_mean-bo_records_std, bo_records_mean+bo_records_std, alpha=0.4)\n",
    "\n",
    "plt.xlabel(\"Number of molecules queried\")\n",
    "plt.ylabel(\"Top-1 power conversion efficiency\")\n",
    "plt.ylim(0.0, 12.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac81272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"outputs/adkt_bo_records.pkl\", \"wb\") as output_file:\n",
    "    pickle.dump(bo_records, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83896349",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
