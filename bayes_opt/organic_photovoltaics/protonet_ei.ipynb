{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c583b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pyprojroot import here as project_root\n",
    "\n",
    "sys.path.insert(0, str(project_root()))\n",
    "\n",
    "from fs_mol.data.dkt import get_dkt_batcher\n",
    "from fs_mol.utils.torch_utils import torchify\n",
    "\n",
    "from bayes_opt.bo_utils import load_cep_dataset, run_gp_ei_bo, min_so_far, task_to_batches, PrototypicalNetworkFeatureExtractor\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b7123ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = load_cep_dataset(\"cep-dataset-subsampled.csv\", \"../../fs_mol/preprocessing/utils/helper_files/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eec150c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batcher = get_dkt_batcher(max_num_graphs=100)\n",
    "dkt_batches = torchify(\n",
    "    task_to_batches(task, batcher), \n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "532dfce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PrototypicalNetworkFeatureExtractor(\n",
       "  (graph_feature_extractor): GraphFeatureExtractor(\n",
       "    (init_node_proj): Linear(in_features=32, out_features=128, bias=False)\n",
       "    (gnn): GNN(\n",
       "      (gnn_blocks): ModuleList(\n",
       "        (0): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (6): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (7): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (8): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (9): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (readout): CombinedGraphReadout(\n",
       "      (_weighted_mean_pooler): MultiHeadWeightedGraphReadout(\n",
       "        (_scoring_module): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=12, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_transformation_mlp): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_combination_layer): Linear(in_features=768, out_features=512, bias=False)\n",
       "      )\n",
       "      (_weighted_sum_pooler): MultiHeadWeightedGraphReadout(\n",
       "        (_scoring_module): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=12, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_transformation_mlp): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_combination_layer): Linear(in_features=768, out_features=512, bias=False)\n",
       "      )\n",
       "      (_max_pooler): UnweightedGraphReadout(\n",
       "        (_combination_layer): Linear(in_features=1408, out_features=512, bias=False)\n",
       "      )\n",
       "      (_combination_layer): Linear(in_features=1536, out_features=512, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2560, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_weights_file = \"../../../fs-mol-checkpoints/PNSupport64_best_validation.pt\"\n",
    "\n",
    "protonet_model = PrototypicalNetworkFeatureExtractor.build_from_model_file(\n",
    "    model_weights_file,\n",
    "    device=device\n",
    ").to(device)\n",
    "\n",
    "protonet_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8645752d",
   "metadata": {},
   "outputs": [],
   "source": [
    "representations = []\n",
    "\n",
    "for features in dkt_batches:\n",
    "    representation = protonet_model.get_representation(features)\n",
    "    representations.append(representation)\n",
    "    \n",
    "del protonet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90211d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = task.samples\n",
    "\n",
    "x_all = torch.cat(representations, dim=0)\n",
    "y_all = torch.FloatTensor([float(x.numeric_label) for x in dataset]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7406af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_init_points = 16\n",
    "query_batch_size = 1\n",
    "num_bo_iters = 40\n",
    "kernel_type = \"matern\"\n",
    "init_from = 1200\n",
    "noise_init = 0.01\n",
    "noise_prior = True\n",
    "\n",
    "num_repeats = 20\n",
    "\n",
    "bo_records = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fc4efa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [45:58<00:00, 137.92s/it]\n"
     ]
    }
   ],
   "source": [
    "for repeat in tqdm(range(num_repeats)):\n",
    "    bo_record = run_gp_ei_bo(dataset, x_all, y_all, num_init_points, query_batch_size, num_bo_iters, kernel_type, device, init_from, noise_init, noise_prior)\n",
    "    bo_records.append(min_so_far(bo_record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4752fcaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 12.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_axis = np.arange(query_batch_size*num_bo_iters+1)\n",
    "\n",
    "bo_records = np.array([[float(-1.0 * y_all[i].item()) for i in bo_record] for bo_record in bo_records])\n",
    "bo_records_mean = bo_records.mean(axis=0)\n",
    "bo_records_std = bo_records.std(axis=0)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "plt.plot(x_axis, bo_records_mean)\n",
    "plt.fill_between(x_axis, bo_records_mean-bo_records_std, bo_records_mean+bo_records_std, alpha=0.4)\n",
    "\n",
    "plt.xlabel(\"Number of molecules queried\")\n",
    "plt.ylabel(\"Top-1 power conversion efficiency\")\n",
    "plt.ylim(0.0, 12.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac81272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"outputs/protonet_bo_records.pkl\", \"wb\") as output_file:\n",
    "    pickle.dump(bo_records, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6b7680",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
