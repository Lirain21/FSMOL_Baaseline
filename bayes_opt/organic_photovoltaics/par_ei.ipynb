{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c583b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [13:23:55] Enabling RDKit 2019.09.3 jupyter extensions\n",
      "[13:23:55] Enabling RDKit 2019.09.3 jupyter extensions\n",
      "/scratches/gauss/wc337/miniconda3/envs/par2/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/scratches/gauss/wc337/miniconda3/envs/par2/lib/python3.8/site-packages/learn2learn/vision/benchmarks/omniglot_benchmark.py:7: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  from PIL.Image import LANCZOS\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pyprojroot import here as project_root\n",
    "\n",
    "sys.path.insert(0, str(project_root()))\n",
    "\n",
    "from fs_mol.data.dkt import get_dkt_batcher\n",
    "from fs_mol.utils.torch_utils import torchify\n",
    "\n",
    "from bayes_opt.bo_utils import load_cep_dataset, run_gp_ei_bo, min_so_far, task_to_batches, PARModelFeatureExtractor\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b7123ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratches/gauss/wc337/miniconda3/envs/par2/lib/python3.8/site-packages/rdkit/Chem/EState/EState.py:48: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  Is = numpy.zeros(nAtoms, numpy.float)\n",
      "/scratches/gauss/wc337/miniconda3/envs/par2/lib/python3.8/site-packages/rdkit/Chem/Graphs.py:43: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  res = numpy.zeros(nAtoms + 1, numpy.float)\n",
      "/scratches/gauss/wc337/miniconda3/envs/par2/lib/python3.8/site-packages/rdkit/Chem/EState/EState_VSA.py:75: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  ans = numpy.zeros(len(bins) + 1, numpy.float)\n"
     ]
    }
   ],
   "source": [
    "task = load_cep_dataset(\"cep-dataset-subsampled.csv\", \"../../fs_mol/preprocessing/utils/helper_files/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ac1070b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batcher = get_dkt_batcher(max_num_graphs=100)\n",
    "dkt_batches = torchify(\n",
    "    task_to_batches(task, batcher), \n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a342b4f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PARModelFeatureExtractor(\n",
       "  (graph_feature_extractor): GraphFeatureExtractor(\n",
       "    (init_node_proj): Linear(in_features=32, out_features=128, bias=False)\n",
       "    (gnn): GNN(\n",
       "      (gnn_blocks): ModuleList(\n",
       "        (0): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (6): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (7): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (8): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (9): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (readout): CombinedGraphReadout(\n",
       "      (_weighted_mean_pooler): MultiHeadWeightedGraphReadout(\n",
       "        (_scoring_module): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=12, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_transformation_mlp): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_combination_layer): Linear(in_features=768, out_features=512, bias=False)\n",
       "      )\n",
       "      (_weighted_sum_pooler): MultiHeadWeightedGraphReadout(\n",
       "        (_scoring_module): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=12, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_transformation_mlp): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_combination_layer): Linear(in_features=768, out_features=512, bias=False)\n",
       "      )\n",
       "      (_max_pooler): UnweightedGraphReadout(\n",
       "        (_combination_layer): Linear(in_features=1408, out_features=512, bias=False)\n",
       "      )\n",
       "      (_combination_layer): Linear(in_features=1536, out_features=512, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (enc_fc): Sequential(\n",
       "    (0): Linear(in_features=2560, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=300, bias=True)\n",
       "  )\n",
       "  (encode_projection): ContextMLP(\n",
       "    (attn_layer): Attention(\n",
       "      (qkv): Linear(in_features=300, out_features=900, bias=False)\n",
       "      (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (mlp_proj): MLP(\n",
       "      (network): Sequential(\n",
       "        (fc0): Linear(in_features=600, out_features=128, bias=True)\n",
       "        (relu0): LeakyReLU(negative_slope=0.01)\n",
       "        (drop0): Dropout(p=0.1, inplace=False)\n",
       "        (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (adapt_relation): TaskAwareRelation(\n",
       "    (predrop1): Dropout(p=0.2, inplace=False)\n",
       "    (edge_layer0): EdgeUpdateNetwork(\n",
       "      (sim_network): Sequential(\n",
       "        (conv0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu0): LeakyReLU(negative_slope=0.01)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu1): LeakyReLU(negative_slope=0.01)\n",
       "        (conv_out): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (node_layer0): NodeUpdateNetwork(\n",
       "      (network): Sequential(\n",
       "        (conv0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu0): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "    )\n",
       "    (edge_layer1): EdgeUpdateNetwork(\n",
       "      (sim_network): Sequential(\n",
       "        (conv0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu0): LeakyReLU(negative_slope=0.01)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu1): LeakyReLU(negative_slope=0.01)\n",
       "        (conv_out): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (node_layer1): NodeUpdateNetwork(\n",
       "      (network): Sequential(\n",
       "        (conv0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu0): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "    )\n",
       "    (fc1): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (predrop2): Dropout(p=0.2, inplace=False)\n",
       "    (fc2): Linear(in_features=128, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_weights_file = \"../../outputs/PAR/best_validation.pt\"\n",
    "\n",
    "par_model = PARModelFeatureExtractor.build_from_model_file(\n",
    "    model_weights_file,\n",
    "    device=device\n",
    ").to(device)\n",
    "\n",
    "par_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5206bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "representations = []\n",
    "\n",
    "for features in dkt_batches:\n",
    "    representation = par_model.get_representation(features)\n",
    "    representations.append(representation)\n",
    "    \n",
    "del par_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34d6a02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = task.samples\n",
    "\n",
    "x_all = torch.cat(representations, dim=0)\n",
    "y_all = torch.FloatTensor([float(x.numeric_label) for x in dataset]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7406af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_init_points = 16\n",
    "query_batch_size = 1\n",
    "num_bo_iters = 40\n",
    "kernel_type = \"matern\"\n",
    "init_from = 1200\n",
    "noise_init = 0.01\n",
    "noise_prior = True\n",
    "\n",
    "num_repeats = 20\n",
    "\n",
    "bo_records = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fc4efa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                        | 0/20 [00:00<?, ?it/s]/scratches/gauss/wc337/miniconda3/envs/par2/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor.py:1811: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755853042/work/aten/src/ATen/native/BatchLinearAlgebra.cpp:1672.)\n",
      "  Linv = torch.triangular_solve(Eye, L, upper=False).solution\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [49:37<00:00, 148.88s/it]\n"
     ]
    }
   ],
   "source": [
    "for repeat in tqdm(range(num_repeats)):\n",
    "    bo_record = run_gp_ei_bo(dataset, x_all, y_all, num_init_points, query_batch_size, num_bo_iters, kernel_type, device, init_from, noise_init, noise_prior)\n",
    "    bo_records.append(min_so_far(bo_record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4752fcaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 12.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_axis = np.arange(query_batch_size*num_bo_iters+1)\n",
    "\n",
    "bo_records = np.array([[float(-1.0 * y_all[i].item()) for i in bo_record] for bo_record in bo_records])\n",
    "bo_records_mean = bo_records.mean(axis=0)\n",
    "bo_records_std = bo_records.std(axis=0)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "plt.plot(x_axis, bo_records_mean)\n",
    "plt.fill_between(x_axis, bo_records_mean-bo_records_std, bo_records_mean+bo_records_std, alpha=0.4)\n",
    "\n",
    "plt.xlabel(\"Number of molecules queried\")\n",
    "plt.ylabel(\"Top-1 power conversion efficiency\")\n",
    "plt.ylim(0.0, 12.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac81272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"outputs/par_bo_records.pkl\", \"wb\") as output_file:\n",
    "    pickle.dump(bo_records, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83896349",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
