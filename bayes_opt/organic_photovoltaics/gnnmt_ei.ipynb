{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c583b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pyprojroot import here as project_root\n",
    "\n",
    "sys.path.insert(0, str(project_root()))\n",
    "\n",
    "from fs_mol.data.multitask import get_multitask_inference_batcher\n",
    "from fs_mol.utils.torch_utils import torchify\n",
    "\n",
    "from fs_mol.models.gnn_multitask import GNNMultitaskModel\n",
    "\n",
    "from bayes_opt.bo_utils import load_cep_dataset, run_gp_ei_bo, min_so_far, task_to_batches\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b7123ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = load_cep_dataset(\"cep-dataset-subsampled.csv\", \"../../fs_mol/preprocessing/utils/helper_files/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ac1070b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batcher = get_multitask_inference_batcher(max_num_graphs=30, device=device)\n",
    "gnnmt_batches = torchify(\n",
    "    task_to_batches(task, batcher), \n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a342b4f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GNNMultitaskModel(\n",
       "  (criterion): BCEWithLogitsLoss()\n",
       "  (graph_feature_extractor): GraphFeatureExtractor(\n",
       "    (init_node_proj): Linear(in_features=32, out_features=128, bias=False)\n",
       "    (gnn): GNN(\n",
       "      (gnn_blocks): ModuleList(\n",
       "        (0): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (6): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (7): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (8): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (9): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (readout): CombinedGraphReadout(\n",
       "      (_weighted_mean_pooler): MultiHeadWeightedGraphReadout(\n",
       "        (_scoring_module): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=12, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_transformation_mlp): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_combination_layer): Linear(in_features=768, out_features=512, bias=False)\n",
       "      )\n",
       "      (_weighted_sum_pooler): MultiHeadWeightedGraphReadout(\n",
       "        (_scoring_module): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=12, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_transformation_mlp): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_combination_layer): Linear(in_features=768, out_features=512, bias=False)\n",
       "      )\n",
       "      (_max_pooler): UnweightedGraphReadout(\n",
       "        (_combination_layer): Linear(in_features=1408, out_features=512, bias=False)\n",
       "      )\n",
       "      (_combination_layer): Linear(in_features=1536, out_features=512, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (tail_mlp): MLP(\n",
       "    (_layers): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=512, out_features=4938, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_weights_file = \"../../../fs-mol-checkpoints/multitask_best_model.pt\"\n",
    "\n",
    "gnnmt_model = GNNMultitaskModel.build_from_model_file(\n",
    "    model_weights_file,\n",
    "    device=device\n",
    ").to(device)\n",
    "\n",
    "gnnmt_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5206bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "representations = []\n",
    "\n",
    "for features in gnnmt_batches:\n",
    "    with torch.no_grad():\n",
    "        representation = gnnmt_model.graph_feature_extractor(features)\n",
    "    representations.append(representation)\n",
    "    \n",
    "del gnnmt_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34d6a02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = task.samples\n",
    "\n",
    "x_all = torch.cat(representations, dim=0)\n",
    "y_all = torch.FloatTensor([float(x.numeric_label) for x in dataset]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7406af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_init_points = 16\n",
    "query_batch_size = 1\n",
    "num_bo_iters = 40\n",
    "kernel_type = \"matern\"\n",
    "init_from = 1200\n",
    "noise_init = 0.01\n",
    "noise_prior = True\n",
    "\n",
    "num_repeats = 20\n",
    "\n",
    "bo_records = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fc4efa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 20/20 [47:58<00:00, 143.95s/it]\n"
     ]
    }
   ],
   "source": [
    "for repeat in tqdm(range(num_repeats)):\n",
    "    bo_record = run_gp_ei_bo(dataset, x_all, y_all, num_init_points, query_batch_size, num_bo_iters, kernel_type, device, init_from, noise_init, noise_prior)\n",
    "    bo_records.append(min_so_far(bo_record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4752fcaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 12.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_axis = np.arange(query_batch_size*num_bo_iters+1)\n",
    "\n",
    "bo_records = np.array([[float(-1.0 * y_all[i].item()) for i in bo_record] for bo_record in bo_records])\n",
    "bo_records_mean = bo_records.mean(axis=0)\n",
    "bo_records_std = bo_records.std(axis=0)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "plt.plot(x_axis, bo_records_mean)\n",
    "plt.fill_between(x_axis, bo_records_mean-bo_records_std, bo_records_mean+bo_records_std, alpha=0.4)\n",
    "\n",
    "plt.xlabel(\"Number of molecules queried\")\n",
    "plt.ylabel(\"Top-1 power conversion efficiency\")\n",
    "plt.ylim(0.0, 12.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac81272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"outputs/gnnmt_bo_records.pkl\", \"wb\") as output_file:\n",
    "    pickle.dump(bo_records, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83896349",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
